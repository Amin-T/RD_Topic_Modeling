{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import liberaries and functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk Disclosures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1698148, 18)\n",
      "Index(['CIK', 'report_dt', 'filing_dt', 'ticker', 'rf_seq', 'SIC', 'TopicWO',\n",
      "       'Topic', 'Topic_H', 'rf_length', 'Pa', 'Pr', 'Fu', 'Sentiment', 'FOG',\n",
      "       'FF', 'Specificity', 'SIC3'],\n",
      "      dtype='object')\n",
      "7169\n"
     ]
    }
   ],
   "source": [
    "# Load RF data \n",
    "topics_df = pd.read_csv(\"Data/RDdf_BERT3.csv\", parse_dates=['report_dt', 'filing_dt'])\n",
    "print(topics_df.shape)\n",
    "print(topics_df.columns)\n",
    "print(topics_df['Topic_H'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify covid 19 topics\n",
    "\n",
    "# BERTopic_info = pd.read_csv(\"BERT/BERTopic_info.csv\").drop(columns='Count')\n",
    "# covid_topics = BERTopic_info[BERTopic_info[\"Representation\"].str.contains(r\"covid\")][\"Topic\"].tolist()\n",
    "# # BERTopic_info[BERTopic_info['Topic'].isin(covid_topics)].set_index(\"Topic\", drop=True).to_records()\n",
    "# covid_topics.remove(11627)\n",
    "# topics_df['Covid_RF'] = topics_df['Topic'].isin(covid_topics).astype(int)\n",
    "\n",
    "BERT_DTM = pd.read_csv(\"BERT/BERTopic_DTM3.csv\")\n",
    "covid_topics = BERT_DTM[BERT_DTM[\"Words\"].str.contains(r\"covid\")][['Topic', 'Timestamp', 'Frequency']]\n",
    "\n",
    "topics_df['Timestamp'] = topics_df['report_dt'].dt.year\n",
    "\n",
    "topics_df['Covid_RF'] = pd.merge(\n",
    "    left=topics_df,\n",
    "    right=covid_topics,\n",
    "    on=['Topic', 'Timestamp'],\n",
    "    how='left'\n",
    ")['Frequency'].notna().astype(int)\n",
    "\n",
    "topics_df.drop(columns='Timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the RF is forward-looking\n",
    "topics_df['Fu_RF'] = (topics_df['Fu']/topics_df[['Pa', 'Pr', 'Fu']].sum(axis=1) > topics_df['Pa']/topics_df[['Pa', 'Pr', 'Fu']].sum(axis=1))\n",
    "\n",
    "# if the RF is backward-looking\n",
    "topics_df['Pa_RF'] = (topics_df['Fu']/topics_df[['Pa', 'Pr', 'Fu']].sum(axis=1) < topics_df['Pa']/topics_df[['Pa', 'Pr', 'Fu']].sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the records at the CIK-year level\n",
    "agg_tops = (\n",
    "    topics_df.groupby([\"CIK\", \"report_dt\", \"filing_dt\", \"FF\"])[\n",
    "        ['SIC3', 'ticker', 'rf_length', 'Specificity', 'Pa_RF', 'Fu_RF', 'Sentiment', 'FOG', 'Covid_RF']\n",
    "    ]\n",
    "    .agg({\n",
    "        'rf_length': 'sum',\n",
    "        'SIC3' : 'unique',\n",
    "        'ticker' : 'unique',\n",
    "        'Specificity': 'sum',\n",
    "        'Pa_RF': 'sum', 'Fu_RF': 'sum',\n",
    "        'Sentiment': 'mean', \n",
    "        'FOG': 'mean',\n",
    "        'Covid_RF': 'sum'\n",
    "    }).reset_index()\n",
    ").drop_duplicates(subset=[\"CIK\", \"filing_dt\", \"report_dt\"]).sort_values([\"CIK\", \"filing_dt\", \"report_dt\"])\n",
    "\n",
    "agg_tops['length_1'] = agg_tops.drop_duplicates(subset=['CIK', 'filing_dt']).groupby([\"CIK\"])['rf_length'].shift(1)\n",
    "agg_tops['length_1'] = agg_tops.groupby('CIK')['length_1'].ffill()\n",
    "agg_tops['Delta_length'] = agg_tops['rf_length'] - agg_tops['length_1']\n",
    "\n",
    "agg_tops[\"ticker\"] = agg_tops[\"ticker\"].map(lambda x: x[0])\n",
    "agg_tops[\"SIC3\"] = agg_tops[\"SIC3\"].map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine generic and non-generic topics\n",
    "topics_df['Topic_freq'] = topics_df.groupby(['Topic_H'])['rf_seq'].transform('count')\n",
    "topics_df['generic'] = (topics_df['Topic_freq']>topics_df[\"Topic_H\"].value_counts().quantile(0.5)).astype(int)\n",
    "\n",
    "df = topics_df[topics_df[\"generic\"]==1].groupby([\"CIK\", \"report_dt\", \"filing_dt\"])['Topic_H']\\\n",
    "        .nunique().rename(\"Generics\").reset_index()\n",
    "\n",
    "agg_tops = pd.merge(\n",
    "    left=agg_tops,\n",
    "    right=df,\n",
    "    on=[\"CIK\", \"filing_dt\", \"report_dt\"],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk factor clusters disclosed and not disclosed per report \n",
    "disc_df = pd.pivot_table(\n",
    "    topics_df, index = [\"CIK\", \"filing_dt\", \"report_dt\"], \n",
    "    columns='Topic_H', values='rf_seq'\n",
    ").notna().astype(int).sort_values([\"CIK\", \"filing_dt\", \"report_dt\"]).reset_index()\n",
    "\n",
    "disc_df['ryear'] = disc_df[\"report_dt\"].dt.year\n",
    "\n",
    "# Drop firm-year observations with more than 1 report in one fiscal year\n",
    "disc_df.drop_duplicates(subset=disc_df.columns.difference([\"filing_dt\", \"report_dt\"]), keep=\"first\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = topics_df['Topic_H'].max() +1\n",
    "# Difference between disclosed risk topics in 2 consecutive years\n",
    "disc_diff = disc_df.filter(range(N)) - disc_df.groupby(\"CIK\")[disc_df.filter(range(N)).columns].shift(1)\n",
    "\n",
    "# Number of added, repeated and removed individual topics\n",
    "disc_df[\"reported\"] = disc_df.filter(range(N)).sum(axis=1)\n",
    "disc_df[\"added\"] = disc_diff.dropna(how='all')[disc_diff>0].sum(axis=1)\n",
    "disc_df[\"removed\"] = disc_diff.dropna(how='all')[disc_diff<0].sum(axis=1)\n",
    "disc_df[\"repeated\"] = disc_df[\"reported\"] - disc_df[\"added\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # duplicated ryears with report at the begining of the year\n",
    "# disc_df['ryear_dupd'] = disc_df.duplicated(subset=['CIK', 'ryear'], keep='last')\n",
    "\n",
    "# disc_df[\"ryear-1\"] = disc_df.groupby('CIK')['ryear'].shift(1)\n",
    "\n",
    "# # change ryear if duplicated and there is a gap between two report years \n",
    "# disc_df['ryear'] = disc_df[['ryear_dupd', 'ryear', 'ryear-1']].apply(\n",
    "#     lambda x: x['ryear']-1 if x['ryear_dupd'] and x['ryear']-1>x['ryear-1'] else x['ryear'],\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# disc_df = disc_df\\\n",
    "#     .drop_duplicates(subset=['CIK', 'ryear'], keep='first')\\\n",
    "#         .reset_index(drop=True).drop(columns=['ryear_dupd', 'ryear-1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = disc_df[['CIK', 'filing_dt', 'report_dt', \n",
    "            'reported', 'repeated', 'added', 'removed']]\n",
    "\n",
    "stat_data = pd.merge(\n",
    "    left=agg_tops,\n",
    "    right=df,\n",
    "    on=['CIK', 'filing_dt', 'report_dt'],\n",
    "    how='left'\n",
    ")\n",
    "# Number of days from fiscal year end and actual filing date\n",
    "stat_data['rfGap'] = (stat_data['filing_dt'] - stat_data['report_dt']).dt.days\n",
    "\n",
    "stat_data['fyear'] = stat_data['filing_dt'].dt.year\n",
    "stat_data['ryear'] = stat_data['report_dt'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\u0147656\\AppData\\Local\\Temp\\ipykernel_18348\\1931497266.py:4: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  CRO['CRO'] = CRO['title'].str.contains(r\"(chief risk)|(risk officer)\", regex=True, case=False).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# If firm appoints a chief risk officer (CRO)\n",
    "CRO = pd.read_csv(\"Data/CRO.csv\")\n",
    "CRO.dropna(subset='title', inplace=True)\n",
    "CRO['CRO'] = CRO['title'].str.contains(r\"(chief risk)|(risk officer)\", regex=True, case=False).astype(int)\n",
    "CRO = CRO.groupby(['year', 'ticker'])['CRO'].max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_data[\"CRO\"] = pd.merge(\n",
    "    left=stat_data,\n",
    "    right=CRO,\n",
    "    left_on=['ryear', 'ticker'],\n",
    "    right_on=['year', 'ticker'],\n",
    "    how='left'\n",
    ")['CRO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BoardEX data\n",
    "compo = pd.read_csv(\"Data/Board-Composition.csv\", \n",
    "                    parse_dates=['AnnualReportDate'], \n",
    "                    usecols=['RoleName', 'AnnualReportDate', 'CIKCode', 'BoardID', 'DirectorID']).drop_duplicates()\n",
    "\n",
    "committees = pd.read_csv(\n",
    "    \"Data/BoardEx_Committees.csv\", parse_dates=['AnnualReportDate']\n",
    ").drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\u0147656\\AppData\\Local\\Temp\\ipykernel_18348\\2998693217.py:2: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  compo['Board_CRO'] = compo['RoleName'].str.contains(r\"(chief risk)|(risk officer)\", regex=True, case=False).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Check CRO in BoardEx database\n",
    "compo['Board_CRO'] = compo['RoleName'].str.contains(r\"(chief risk)|(risk officer)\", regex=True, case=False).astype(int)\n",
    "\n",
    "# If director is in a risk committee\n",
    "committees['RiskCommittee'] = committees['CommitteeName'].str.contains(r\"risk\", case=False).astype(int)\n",
    "\n",
    "# Only directors that are in risk committee (some directors are in multiple committees - to remove duplicates)\n",
    "Risk_committee = committees.loc[\n",
    "    committees['RiskCommittee']==1,\n",
    "    ['AnnualReportDate', 'RiskCommittee', 'BoardID', 'DirectorID']\n",
    "].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "compo = pd.merge(\n",
    "    left=compo,\n",
    "    right=Risk_committee,\n",
    "    on=['AnnualReportDate', 'BoardID', 'DirectorID'],\n",
    "    how='left'\n",
    ").fillna({'RiskCommittee': 0})\n",
    "\n",
    "compo['ryear'] = pd.to_datetime(compo['AnnualReportDate']).dt.year\n",
    "\n",
    "compo_sum = compo.groupby(['CIKCode', 'ryear'])[['Board_CRO', 'RiskCommittee']].agg(\n",
    "    {'Board_CRO': 'max', 'RiskCommittee': 'sum'}\n",
    ").reset_index()\n",
    "\n",
    "compo_sum[['CIKCode', 'ryear']] = compo_sum[['CIKCode', 'ryear']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_data[\"Board_CRO\"] = pd.merge(\n",
    "    left=stat_data,\n",
    "    right=compo_sum,\n",
    "    left_on=['ryear', 'CIK'],\n",
    "    right_on=['ryear', 'CIKCode'],\n",
    "    how='left'\n",
    ")['Board_CRO']\n",
    "\n",
    "stat_data.fillna({\"CRO\": stat_data[\"Board_CRO\"]}, inplace=True)\n",
    "\n",
    "stat_data.drop(columns=['Board_CRO'], inplace=True)\n",
    "\n",
    "stat_data[\"RC\"] = pd.merge(\n",
    "    left=stat_data,\n",
    "    right=compo_sum,\n",
    "    left_on=['ryear', 'CIK'],\n",
    "    right_on=['ryear', 'CIKCode'],\n",
    "    how='left'\n",
    ")['RiskCommittee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_data = pd.read_csv('Data/Study2_data1_V2.csv', parse_dates=['report_dt', 'filing_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different Tobin's Q calculation (Florio et al., 2017)\n",
    "financials = pd.read_csv(\"Data\\Financials3.csv\", parse_dates=['datadate'])\n",
    "financials['ryear'] = financials['datadate'].dt.year\n",
    "financials['rmonth'] = financials['datadate'].dt.month\n",
    "financials[\"TobinQ2\"] = (financials[\"mkvalt\"]+financials[\"lt\"]) / financials[\"at\"].replace(0, np.nan)\n",
    "financials[\"ROA\"] = financials[\"ni\"] / financials[\"at\"].replace(0, np.nan)\n",
    "financials[\"ROA2\"] = financials[\"ebit\"] / financials[\"at\"].replace(0, np.nan)\n",
    "\n",
    "# Calculate industry ROA\n",
    "financials.fillna({'sich': financials['sic']}, inplace=True)\n",
    "financials['SIC3'] = financials['sich'].map(lambda x: f\"{int(x):04d}\"[:3] if ~np.isnan(x) else x)\n",
    "financials['IndROA'] = financials.groupby(['SIC3', 'ryear'])['ROA'].transform('mean')\n",
    "\n",
    "financials['cik'] = financials['cik'].astype(int)\n",
    "\n",
    "# drop duplicated fiscal year/month\n",
    "financials.sort_values([\"cik\", \"ryear\", \"rmonth\", 'TobinQ2'], inplace=True)\n",
    "financials.drop_duplicates(subset=[\"cik\", \"ryear\", \"rmonth\"], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cik', 'datadate', 'act', 'at', 'dt', 'ebit', 'ebitda', 'intan', 'lct',\n",
       "       'lt', 'ni', 'revt', 'seq', 'teq', 'xopr', 'xrd', 'xt', 'naicsh', 'sich',\n",
       "       'mkvalt', 'naics', 'sic', 'ryear', 'rmonth', 'TobinQ2', 'ROA', 'ROA2',\n",
       "       'SIC3', 'IndROA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financials.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38343, 25)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Study3_data = pd.merge(\n",
    "    left=stat_data,\n",
    "    right=other_data[[\n",
    "        'CIK', 'report_dt', 'filing_dt', 'COUNT_WEAK', 'Big4', 'GenderRatio', 'NumberDirectors', 'Age',\n",
    "        'LnkdFirm', 'Independent', 'Volatility+30', 'Volatility_30', 'Volatility+60', 'Volatility_120', \n",
    "        'SHRTURN', 'Beta_126', 'NUMBEROFANALYSTS', 'DtA', 'ROE', 'NPM', 'mkvalt', 'logMC', 'at', 'logTA', \n",
    "        'INTtA', 'Current', 'TobinQ', 'BtM', 'RDxopr', 'ProprietaryCost', 'IndVol_', 'InstOwnership', 'ROA',\n",
    "    ]],\n",
    "    on=['CIK', 'filing_dt', 'report_dt'],\n",
    "    how='left'\n",
    ").drop(columns='ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Study3_data[\"rmonth\"] = Study3_data['report_dt'].dt.month\n",
    "\n",
    "Study3_data = pd.merge(\n",
    "    left=Study3_data,\n",
    "    right=financials[['cik', 'ryear', 'rmonth', 'TobinQ2', 'IndROA', 'ROA2']],\n",
    "    left_on=[\"CIK\", \"ryear\", \"rmonth\"],\n",
    "    right_on=[\"cik\", \"ryear\", \"rmonth\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "financials.sort_values([\"cik\", \"ryear\", 'TobinQ2'], inplace=True)\n",
    "financials.drop_duplicates(subset=[\"cik\", \"ryear\"], keep='first', inplace=True)\n",
    "\n",
    "df = pd.merge(\n",
    "    left=Study3_data,\n",
    "    right=financials[['cik', 'ryear', 'TobinQ2', 'IndROA', 'ROA2']],\n",
    "    left_on=[\"CIK\", \"ryear\"],\n",
    "    right_on=[\"cik\", \"ryear\"],\n",
    "    how=\"left\",\n",
    "    suffixes=['', '_2']\n",
    ")\n",
    "\n",
    "Study3_data.fillna({'TobinQ2': df['TobinQ2_2']}, inplace=True)\n",
    "Study3_data.fillna({'IndROA': df['IndROA_2']}, inplace=True)\n",
    "Study3_data.fillna({'ROA2': df['ROA2_2']}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38111, 57)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Study3_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Study3_data.to_csv(\"Data/Study3_V2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CIK', 'ryear', 'report_dt', 'filing_dt', 'FF', 'rf_length', 'SIC3',\n",
       "       'Specificity', 'Pa_RF', 'Fu_RF', 'Sentiment', 'FOG', 'Covid_RF',\n",
       "       'length_1', 'Delta_length', 'Generics', 'reported', 'repeated', 'added',\n",
       "       'removed', 'rfGap', 'fyear', 'CRO', 'RC', 'COUNT_WEAK', 'Big4',\n",
       "       'GenderRatio', 'NumberDirectors', 'Age', 'LnkdFirm', 'Independent',\n",
       "       'Volatility+30', 'Volatility_30', 'Volatility+60', 'Volatility_120',\n",
       "       'SHRTURN', 'Beta_126', 'NUMBEROFANALYSTS', 'DtA', 'ROE', 'NPM',\n",
       "       'mkvalt', 'logMC', 'at', 'logTA', 'INTtA', 'Current', 'TobinQ', 'BtM',\n",
       "       'RDxopr', 'ProprietaryCost', 'IndVol_', 'InstOwnership', 'ROA',\n",
       "       'TobinQ2', 'IndROA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Study3_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PhD_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
