{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import liberaries and functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk disclosure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3245397, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Topic', 'Score', 'Topic_H', 'Score_H', 'CIK', 'report_dt', 'filing_dt',\n",
       "       'rf_seq', 'ticker', 'filerCIK', 'rf_length', 'NERs', 'Pa', 'Pr', 'Fu',\n",
       "       'Sentiment', 'FOG', 'SIC', 'FF', 'ryear', 'fyear', 'rf_seq_count',\n",
       "       'Specificity', 'SIC3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load RF data \n",
    "topics_df = pd.read_csv(\"Data/RDdf_T2V5.csv\", parse_dates=['report_dt', 'filing_dt'])\n",
    "\n",
    "topics_df['NERs'] = topics_df['NERs'].str.replace(pat=\" \", repl=\"\").str.findall(pat=r\"'(.*?)'\")\n",
    "\n",
    "NE_labels = ['PERSON', 'NORP' 'ORG', 'GPE', 'LOC', 'PRODUCT', 'EVENT', 'LAW', 'DATE', 'TIME', 'PERCENT', 'MONEY', 'QUANTITY']\n",
    "topics_df['Specificity'] = topics_df['NERs'].apply(lambda NERs: len([ne for ne in NERs if ne in NE_labels]))\n",
    "\n",
    "topics_df['SIC3'] = topics_df['SIC'].map(lambda x: f\"{int(x):04d}\"[:3])\n",
    "\n",
    "print(topics_df.shape)\n",
    "topics_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = topics_df['Topic_H'].nunique()\n",
    "# Risk topics disclosed and not disclosed per report \n",
    "disc_df = pd.pivot_table(\n",
    "    topics_df, index = [\"CIK\", \"filing_dt\", \"report_dt\", \"FF\"], \n",
    "    columns='Topic_H', values='Score'\n",
    ").notna().astype(int).reset_index()\n",
    "\n",
    "# Long format\n",
    "disc_long = pd.melt(disc_df, id_vars=[\"CIK\", \"filing_dt\", \"report_dt\", \"FF\"], value_name='Disclosed')\n",
    "disc_long.sort_values([\"CIK\", 'Topic_H', \"filing_dt\", \"report_dt\"], inplace=True)\n",
    "\n",
    "disc_long['DiscSum'] = disc_long.groupby([\"CIK\", 'Topic_H'])['Disclosed'].cumsum()\n",
    "\n",
    "# Total number of risk topics\n",
    "disc_long['TotalRFs'] = disc_long.groupby([\"CIK\", \"filing_dt\", \"report_dt\"])['Disclosed'].transform('sum')\n",
    "\n",
    "# Difference between disclosed risk topics in 2 consecutive years\n",
    "disc_diff = disc_df.filter(range(N)) - disc_df.groupby(\"CIK\")[disc_df.filter(range(N)).columns].shift(1)\n",
    "\n",
    "# Repeated risk factors\n",
    "disc_repeat = (\n",
    "    disc_df.filter(range(N))\n",
    "    + disc_df.groupby(\"CIK\")[disc_df.filter(range(N)).columns].shift(1) \n",
    "    == 2\n",
    ").astype(int)\n",
    "\n",
    "# Whether risk factor was disclosed in the previouse year's report\n",
    "disc_long['LstYrDisc'] = disc_long.drop_duplicates(subset=['CIK', 'Topic_H', 'filing_dt']).groupby(['CIK', 'Topic_H'])['Disclosed'].shift(1)\n",
    "disc_long['LstYrDisc'] = disc_long.groupby(['CIK', 'Topic_H'])['LstYrDisc'].ffill()\n",
    "\n",
    "# Generate added, repeated and removed dummies\n",
    "disc_long['New'] = ((disc_long['LstYrDisc']==0)&(disc_long['Disclosed']==1)).astype(int)\n",
    "disc_long['Removed'] = ((disc_long['LstYrDisc']==1)&(disc_long['Disclosed']==0)).astype(int)\n",
    "disc_long['Repeated'] = ((disc_long['LstYrDisc']==1)&(disc_long['Disclosed']==1)).astype(int)\n",
    "\n",
    "# Whether risk factor was newly disclosed in the previouse year's report\n",
    "disc_long['LstYrNew'] = disc_long.groupby(['CIK', 'Topic_H'])['New'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep RFs that if disclosed, they are either added or repeated\n",
    "disc_long = (\n",
    "    disc_long[disc_long[['New', 'Repeated']]\n",
    "              .sum(axis=1)==disc_long['Disclosed']]\n",
    "              .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Number of days from fiscal year end and actual filing date\n",
    "disc_long['rfGap'] = (disc_long['filing_dt'] - disc_long['report_dt']).dt.days\n",
    "\n",
    "disc_long['fyear'] = disc_long[\"filing_dt\"].dt.year\n",
    "disc_long['ryear'] = disc_long[\"report_dt\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of disclosed RFs as the total number of words \n",
    "length_df = pd.pivot_table(\n",
    "    topics_df, index = [\"CIK\", \"filing_dt\", \"report_dt\"], \n",
    "    columns='Topic_H', values='rf_length', aggfunc='sum',\n",
    "    fill_value=0 # NA length means not disclosed so equal to 0\n",
    ").reset_index()\n",
    "\n",
    "# Long format\n",
    "length_long = pd.melt(length_df, id_vars=[\"CIK\", \"filing_dt\", \"report_dt\"], value_name='RF_length')\n",
    "length_long.sort_values([\"CIK\", \"Topic_H\", \"filing_dt\", \"report_dt\"], inplace=True)\n",
    "\n",
    "# Length of the topics last year\n",
    "length_long['length_1'] = length_long.drop_duplicates(subset=['CIK', 'Topic_H', 'filing_dt']).groupby([\"CIK\", \"Topic_H\"])['RF_length'].shift(1)\n",
    "length_long['length_1'] = length_long.groupby(['CIK', 'Topic_H'])['length_1'].ffill()\n",
    "\n",
    "disc_long = pd.merge(\n",
    "    left=disc_long,\n",
    "    right=length_long,\n",
    "    on=['CIK', 'filing_dt', 'report_dt', 'Topic_H'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Industry disclosure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_df[\"filing_dt-1\"] = disc_df[\"filing_dt\"] - pd.Timedelta(weeks=52)\n",
    "\n",
    "def count_func(x):\n",
    "    \"\"\"\n",
    "    Counts the number of firms in the industry that disclose a specific RF.\n",
    "    \"\"\"\n",
    "    df_slice = disc_df[\n",
    "        (disc_df[\"filing_dt\"]>x[\"filing_dt-1\"])\n",
    "        &(disc_df[\"filing_dt\"]<=x[\"filing_dt\"])\n",
    "        &(disc_df['FF']==x['FF'])\n",
    "    ]\n",
    "    output = (\n",
    "        df_slice[df_slice['CIK']!=x['CIK']].filter(range(N)).sum() / df_slice[\"filing_dt\"].count()\n",
    "    )\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Running the function on disc_df\n",
    "IndDisc_df = disc_df.drop(columns=range(N)).copy()\n",
    "IndDisc_df.loc[:, range(N)] = disc_df.apply(count_func, axis=1)\n",
    "IndDisc_df.drop(columns=['filing_dt-1'], inplace=True)\n",
    "\n",
    "# Create the data in long format\n",
    "Inddisc_long = pd.melt(IndDisc_df, id_vars=[\"CIK\", \"filing_dt\", \"report_dt\", \"FF\"], value_name='IndDisc')\n",
    "\n",
    "# Drop RFs that have never been disclosed per industry \n",
    "Inddisc_long = Inddisc_long[Inddisc_long.groupby(['FF', 'Topic_H'])['IndDisc'].transform('sum')>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_long['IndDisc'] = pd.merge(\n",
    "    left=disc_long,\n",
    "    right=Inddisc_long,\n",
    "    on=[\"CIK\", \"filing_dt\", \"report_dt\", \"Topic_H\"],\n",
    "    how='left'\n",
    ")['IndDisc']\n",
    "\n",
    "disc_long.fillna({'IndDisc': 0}, inplace=True)\n",
    "disc_long.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Industry disclosure change\n",
    "disc_long['IndDisc_1'] = disc_long.drop_duplicates(subset=['CIK', 'Topic_H', 'filing_dt']).groupby(['CIK', 'Topic_H'])['IndDisc'].shift(1)\n",
    "disc_long['IndDisc_1'] = disc_long.groupby(['CIK', 'Topic_H'])['IndDisc_1'].ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linked firm disclosures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The independent variable shows how many of the firms linked to the focal firm at a specific year have disclosed the Added, Repeated or Removed risk factors in their corresponding annual report. \n",
    "At year ryear for firm CIK, we look at the linked firms in Year and count the number of disclosures in reporting year ryear. At a specfic reporting year, all firms are assumed to be exposed to similar risks. It is not important if one is reporting sooner or later.\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BoardEX data\n",
    "compo = pd.read_csv(\"Data/Board-Composition.csv\", parse_dates=['AnnualReportDate']).drop(columns='Ticker').drop_duplicates()\n",
    "\n",
    "compo['Year'] = pd.to_datetime(compo['AnnualReportDate']).dt.year\n",
    "\n",
    "# Calculate number of DirectorID shared with other BoardID per year\n",
    "link_df = pd.merge(\n",
    "    left=compo[['BoardID', 'DirectorID', 'Year', 'CIKCode']],\n",
    "    right=compo[['DirectorID', 'Year', 'BoardID', 'CIKCode']],\n",
    "    on=['DirectorID', 'Year'],\n",
    "    how='outer',\n",
    "    suffixes=[\"\", \"_lnkd\"]\n",
    ")\n",
    "\n",
    "link_df = link_df[link_df['BoardID']!=link_df['BoardID_lnkd']]\n",
    "\n",
    "link_df = link_df.dropna(subset=['CIKCode', 'CIKCode_lnkd']).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Link age\n",
    "link_df = link_df.sort_values(['BoardID', 'BoardID_lnkd', 'Year']).reset_index(drop=True)\n",
    "link_df['LinkTime'] = link_df.drop_duplicates(subset=['BoardID', 'BoardID_lnkd', 'Year']).groupby(['BoardID', 'BoardID_lnkd'])['Year'].cumcount()+1\n",
    "link_df['LinkTime'] = link_df['LinkTime'].ffill()\n",
    "\n",
    "# List of linked firms\n",
    "lnkdCIKs = link_df.groupby(['CIKCode', 'Year'])['CIKCode_lnkd'].agg(lambda x: list(x))\n",
    "\n",
    "disc_df['ryear'] = disc_df['report_dt'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LnkDisc: Number of linked firms that disclose each RT in the same ryear\\\n",
    "OldLnkNewDisc: Number of firms linked for more than 1 year that disclose new RT in the same ryear\\\n",
    "NewLnkLstyrDisc: Number of new linked firms that disclosed each RT in the last ryear\\\n",
    "NewLnkRepDisc: Number of new linked firms that repeat each RT in ryear (disclosed last year and this year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnkd_disc_count(x):\n",
    "    \"\"\"\n",
    "    Counts the number of linked firms that disclose a specific RF in year ryear.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        output = disc_df[\n",
    "            (disc_df['CIK'].isin(lnkdCIKs.loc[tuple(x[['CIK', 'ryear']])]))\n",
    "            &(disc_df['ryear']==x['ryear'])\n",
    "        ].filter(range(N)).sum()\n",
    "    except:\n",
    "        output = np.nan\n",
    "\n",
    "    return output\n",
    "\n",
    "# Running the function on disc_df\n",
    "LnkdDisc_df = disc_df.drop(columns=range(N)).copy()\n",
    "LnkdDisc_df.loc[:, range(N)] = disc_df.apply(lnkd_disc_count, axis=1)\n",
    "LnkdDisc_df.drop(columns=['filing_dt-1', 'ryear', 'FF'], inplace=True)\n",
    "\n",
    "# Create the data in long format - \n",
    "LnkdDisc_long = pd.melt(LnkdDisc_df, id_vars=[\"CIK\", \"filing_dt\", \"report_dt\"], value_name='LnkDisc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H: Connected firms A and B add new RF at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of linked CIKs of more than 1 year old\n",
    "OldlnkdCIKs = link_df[link_df['LinkTime']>1].groupby(['CIKCode', 'Year'])['CIKCode_lnkd'].agg(lambda x: list(x))\n",
    "\n",
    "# Count the number of old linked firms disclosing new RF\n",
    "disc_new_df = pd.concat([disc_df[['CIK', 'filing_dt', 'report_dt', 'ryear']], (disc_diff>0).astype(int)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnkd_new_count(x):\n",
    "    \"\"\"\n",
    "    Counts the number of old linked firms that disclose a new RF in year ryear.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        output = disc_new_df[\n",
    "            (disc_new_df['CIK'].isin(OldlnkdCIKs.loc[tuple(x[['CIK', 'ryear']])]))\n",
    "            &(disc_new_df['ryear']==x['ryear'])\n",
    "        ].filter(range(N)).sum()\n",
    "    except:\n",
    "        output = np.nan\n",
    "\n",
    "    return output\n",
    "\n",
    "# Running the function on disc_df\n",
    "LnkdRep_df = disc_df.drop(columns=range(N)).copy()\n",
    "LnkdRep_df.loc[:, range(N)] = disc_df.apply(lnkd_new_count, axis=1)\n",
    "LnkdRep_df.drop(columns=['filing_dt-1', 'ryear', 'FF'], inplace=True)\n",
    "\n",
    "# Create the data in long format\n",
    "LnkdRep_long = pd.melt(LnkdRep_df, id_vars=[\"CIK\", \"filing_dt\", \"report_dt\"], \n",
    "                       var_name='Topic_H', value_name='OldLnkNewDisc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H: Firm A connects with B in year t, it adds RFs disclosed by B in year t-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of new linked CIKs\n",
    "NewlnkdCIKs = link_df[link_df['LinkTime']==1].groupby(['CIKCode', 'Year'])['CIKCode_lnkd'].agg(lambda x: list(x))\n",
    "\n",
    "disc_lstyr_df = pd.concat([disc_df[['CIK', 'filing_dt', 'report_dt', 'ryear']], \n",
    "                           disc_df.groupby(\"CIK\")[list(range(N))].shift(1)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def New_lnkd_LstYr_count(x):\n",
    "    \"\"\"\n",
    "    Counts the number of New linked firms that disclose a specific RF in year ryear-1.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        output = disc_lstyr_df[\n",
    "            (disc_lstyr_df['CIK'].isin(NewlnkdCIKs.loc[tuple(x[['CIK', 'ryear']])]))\n",
    "            &(disc_lstyr_df['ryear']==x['ryear'])\n",
    "        ].filter(range(N)).sum()\n",
    "    except:\n",
    "        output = pd.Series(np.ones((N,))*np.nan)\n",
    "\n",
    "    return output\n",
    "\n",
    "# Running the function on disc_df\n",
    "NewLnkdDisc_df = disc_df.drop(columns=range(N)).copy()\n",
    "NewLnkdDisc_df.loc[:, range(N)] = disc_df.apply(New_lnkd_LstYr_count, axis=1)\n",
    "NewLnkdDisc_df.drop(columns=['filing_dt-1', 'ryear', 'FF'], inplace=True)\n",
    "\n",
    "# Create the data in long format\n",
    "NewLnkdDisc_long = pd.melt(NewLnkdDisc_df, id_vars=[\"CIK\", \"filing_dt\", \"report_dt\"], value_name='NewLnkLstyrDisc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For additional analysis to check if a risk topic transfered from one firm to another is less specific\n",
    "def lnkd_LstYr_count(x):\n",
    "    \"\"\"\n",
    "    Counts the number of New linked firms that disclose a specific RF in year ryear-1.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        output = disc_lstyr_df[\n",
    "            (disc_lstyr_df['CIK'].isin(lnkdCIKs.loc[tuple(x[['CIK', 'ryear']])]))\n",
    "            &(disc_lstyr_df['ryear']==x['ryear'])\n",
    "        ].filter(range(N)).sum()\n",
    "    except:\n",
    "        output = pd.Series(np.ones((N,))*np.nan)\n",
    "\n",
    "    return output\n",
    "\n",
    "# Running the function on disc_df\n",
    "LnkLstyrDisc_df = disc_df.drop(columns=range(N)).copy()\n",
    "LnkLstyrDisc_df.loc[:, range(N)] = disc_df.apply(lnkd_LstYr_count, axis=1)\n",
    "LnkLstyrDisc_df.drop(columns=['filing_dt-1', 'ryear', 'FF'], inplace=True)\n",
    "\n",
    "# Create the data in long format\n",
    "LnkLstyrDisc_long = pd.melt(LnkLstyrDisc_df, id_vars=[\"CIK\", \"filing_dt\", \"report_dt\"], value_name='LnkLstyrDisc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_repeat_df = pd.concat([disc_df[['CIK', 'filing_dt', 'report_dt', 'ryear']], disc_repeat], axis=1)\n",
    "\n",
    "def New_lnkd_repeat_count(x):\n",
    "    \"\"\"\n",
    "    Counts the number of linked firms that repeat a specific RF in year ryear.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        output = disc_repeat_df[\n",
    "            (disc_repeat_df['CIK'].isin(NewlnkdCIKs.loc[tuple(x[['CIK', 'ryear']])]))\n",
    "            &(disc_repeat_df['ryear']==x['ryear'])\n",
    "        ].filter(range(N)).sum()\n",
    "    except:\n",
    "        output = pd.Series(np.ones((N,))*np.nan)\n",
    "\n",
    "    return output\n",
    "\n",
    "# Running the function on disc_df\n",
    "NewLnkdRep_df = disc_repeat_df.drop(columns=range(N)).copy()\n",
    "NewLnkdRep_df.loc[:, range(N)] = disc_repeat_df.apply(New_lnkd_repeat_count, axis=1)\n",
    "NewLnkdRep_df.drop(columns=['ryear'], inplace=True)\n",
    "\n",
    "# Create the data in long format\n",
    "NewLnkdRep_long = pd.melt(NewLnkdRep_df, id_vars=[\"CIK\", \"filing_dt\", \"report_dt\"], \n",
    "                       var_name='Topic_H', value_name='NewLnkRepDisc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_long['LnkDisc'] = pd.merge(\n",
    "    left=disc_long,\n",
    "    right=LnkdDisc_long,\n",
    "    on=[\"CIK\", \"filing_dt\", \"report_dt\", \"Topic_H\"],\n",
    "    how='left'\n",
    ")['LnkDisc']\n",
    "\n",
    "disc_long['OldLnkNewDisc'] = pd.merge(\n",
    "    left=disc_long,\n",
    "    right=LnkdRep_long,\n",
    "    on=[\"CIK\", \"filing_dt\", \"report_dt\", \"Topic_H\"],\n",
    "    how='left'\n",
    ")['OldLnkNewDisc']\n",
    "\n",
    "disc_long['NewLnkLstyrDisc'] = pd.merge(\n",
    "    left=disc_long,\n",
    "    right=NewLnkdDisc_long,\n",
    "    on=[\"CIK\", \"filing_dt\", \"report_dt\", \"Topic_H\"],\n",
    "    how='left'\n",
    ")['NewLnkLstyrDisc']\n",
    "\n",
    "disc_long['NewLnkRepDisc'] = pd.merge(\n",
    "    left=disc_long,\n",
    "    right=NewLnkdRep_long,\n",
    "    on=[\"CIK\", \"filing_dt\", \"report_dt\", \"Topic_H\"],\n",
    "    how='left'\n",
    ")['NewLnkRepDisc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "FirmData = pd.read_csv('Data\\Study2_data1_V2.csv', parse_dates=[\"filing_dt\", \"report_dt\"])\\\n",
    "    .drop(columns=['FF', 'rf_length', 'SIC3', 'Delta_length', 'reported', \n",
    "                   'repeated', 'added', 'removed', 'rfGap', 'fyear', 'ryear', 'cik'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop RTs never disclosed disclosed in industry\n",
    "disc_long = disc_long[disc_long.groupby(['FF', 'Topic_H'])['IndDisc'].transform('sum')>0].reset_index(drop=True)\n",
    "\n",
    "# Drop RTs never disclosed and always disclosed\n",
    "disc_long = disc_long[disc_long.groupby(['CIK', 'Topic_H'])['DiscSum'].transform('max')>0]\n",
    "disc_long = disc_long[disc_long.groupby(['CIK', 'Topic_H'])['DiscSum'].transform('min')<2]\n",
    "\n",
    "# Drop the first year of every firm observation\n",
    "disc_long.dropna(subset=['LstYrDisc'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Study2_data = pd.merge(\n",
    "    left=disc_long,\n",
    "    right=FirmData,\n",
    "    on=['CIK', 'filing_dt', 'report_dt'],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CIK', 'FF', 'Topic_H', 'Disclosed', 'DiscSum', 'TotalRFs', 'LstYrDisc',\n",
       "       'New', 'Removed', 'Repeated', 'LstYrNew', 'rfGap', 'fyear', 'ryear',\n",
       "       'RF_length', 'length_1', 'IndDisc', 'IndDisc_1', 'LnkDisc',\n",
       "       'OldLnkNewDisc', 'NewLnkLstyrDisc', 'NewLnkRepDisc', 'Specificity',\n",
       "       'Pa', 'Pr', 'Fu', 'Sentiment', 'FOG', 'added+1', 'removed+1',\n",
       "       'COUNT_WEAK', 'Big4', 'TimeInCo', 'NoQuals', 'GenderRatio',\n",
       "       'NationalityMix', 'NumberDirectors', 'NetworkSize', 'TotCurrBrd', 'Age',\n",
       "       'ShrdDir', 'LnkdFirm', 'ShrdED', 'ShrdRiskDir', 'FinLink', 'Degree',\n",
       "       'LinkTime', 'D_NumberDirectors', 'D_ShrdDir', 'D_LnkdFirm', 'D_ShrdED',\n",
       "       'D_ShrdRiskDir', 'D_Degree', 'Volatility+30', 'Volatility_30',\n",
       "       'Volatility+60', 'Volatility_120', 'SHRTURN', 'Beta_126',\n",
       "       'NUMBEROFANALYSTS', 'rmonth', 'DtA', 'ROE', 'NPM', 'mkvalt', 'logMC',\n",
       "       'at', 'logTA', 'INTtA', 'Current', 'TobinQ', 'BtM', 'RDxopr',\n",
       "       'ProprietaryCost', 'IndVol_', 'IndVol+', 'InstOwnership'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Study2_data.drop(columns=['filing_dt', 'report_dt'], inplace=True)\n",
    "Study2_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Study2_data = Study2_data[Study2_data.groupby('CIK')['ryear'].transform('nunique')>1]\n",
    "Study2_data.dropna(subset=['Volatility_120', 'NumberDirectors'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1260878, 77)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Study2_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Study2_data.to_csv(\"Data/Study2_data2_V2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the observations in main sample and linked firms. \n",
    "# Fill the linked firms of missing observations in BoardEX with last year links\n",
    "lnkdCIKs = pd.merge(\n",
    "    left=disc_long[['CIK', 'ryear']].drop_duplicates(),\n",
    "    right=lnkdCIKs,\n",
    "    left_on=['CIK', 'ryear'],\n",
    "    right_index=True,\n",
    "    how='outer'\n",
    ").set_index(['CIK', 'ryear']).groupby('CIK').ffill(limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([link_df, compo[['BoardID', 'DirectorID', 'Year', 'CIKCode', 'ED', 'RiskCommittee']]])\n",
    "df.sort_values(['BoardID', 'DirectorID', 'Year'], inplace=True)\n",
    "df = df[(~df.duplicated(subset=['BoardID', 'DirectorID', 'Year', 'CIKCode'], keep=False))|(~df['BoardID_lnkd'].isna())]\n",
    "df['SharedDir'] = df['BoardID_lnkd'].notna().astype(int)\n",
    "df = df[df.groupby(['BoardID', 'DirectorID'])['SharedDir'].transform('max')>0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ETM_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e814d5f901f2e2f1812217256e7a2386c6b3dac449e52472436b21a420d1617"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
