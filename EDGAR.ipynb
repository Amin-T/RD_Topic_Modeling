{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e910260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from multiprocessing import Pool\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a730891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !python -m spacy download en_core_web_sm\n",
    "# import spacy\n",
    "\n",
    "# nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ef4eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_request(url, params=None, headers=None, max_retries = 5):\n",
    "\n",
    "    current_tries = 1\n",
    "    while current_tries < max_retries:\n",
    "        response = requests.get(url=url, params=params, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response\n",
    "        else:\n",
    "            time.sleep(1)\n",
    "            current_tries += 1\n",
    "            \n",
    "    return requests.get(url=url, params=params, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e4688d",
   "metadata": {},
   "source": [
    "# Companies by SIC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a9a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIC_search(search_params):\n",
    "    \"\"\"\n",
    "    Search the list of companies by SIC code\n",
    "    >>> https://www.sec.gov/cgi-bin/browse-edgar?company=&match=&filenum=&State=&Country=&SIC=1000&myowner=exclude&action=getcompany\n",
    "    \"\"\"\n",
    "    \n",
    "    url = \"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
    "    \n",
    "    headers = {\n",
    "        'User-Agent': 'kuleuven amin.tavakkolnia@kuleuven.be',\n",
    "        'Host': 'www.sec.gov'\n",
    "    }\n",
    "\n",
    "    res = make_request(url, params=search_params, headers=headers, max_retries=10)\n",
    "\n",
    "    search = BeautifulSoup(res.content, 'html.parser')\n",
    "    \n",
    "    try:\n",
    "        search_df = pd.read_html(str(search.table))[0]\n",
    "        search_df['SIC'] = search_params['SIC']\n",
    "        return search_df\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d47e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retreive list of all SIC codes from www.sec.gov\n",
    "res = make_request(\n",
    "    url='https://www.sec.gov/search-filings/standard-industrial-classification-sic-code-list',\n",
    "    headers = {\n",
    "        'User-Agent': 'kuleuven amin.tavakkolnia@kuleuven.be',\n",
    "        'Host': 'www.sec.gov'\n",
    "    }\n",
    ")\n",
    "SIC_list = pd.read_html(res.content)[0]\n",
    "SIC_list.to_excel('SIC_list.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa34e6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIC_list = pd.read_excel('SIC_list.xlsx')\n",
    "SIC_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab6f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = pd.DataFrame()\n",
    "\n",
    "for i, sic in enumerate(SIC_list.index):\n",
    "    start_cnt = 0\n",
    "    search_params = {\n",
    "        'action': 'getcompany',\n",
    "        'SIC': sic,\n",
    "        'start': start_cnt,\n",
    "        'count': 100,\n",
    "        'owner': 'include'\n",
    "    }\n",
    "    com = SIC_search(search_params)\n",
    "\n",
    "    while com is not None:\n",
    "        com['Industry'] = SIC_list.loc[sic, 'Office']\n",
    "        all_companies = pd.concat([all_companies, com])\n",
    "        start_cnt += 100\n",
    "        search_params = {\n",
    "            'action': 'getcompany',\n",
    "            'SIC': sic,\n",
    "            'start': start_cnt,\n",
    "            'count': 100,\n",
    "            'owner': 'include'\n",
    "        }\n",
    "        com = SIC_search(search_params)\n",
    "\n",
    "    if i%50 == 0:\n",
    "        print(f\"{i} SICs added\")\n",
    "        all_companies.to_csv('all_companies.csv', index=False)\n",
    "    time.sleep(1)\n",
    "    \n",
    "all_companies.to_excel('all_companies.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db23295d",
   "metadata": {},
   "source": [
    "# Get list of filings per company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cba731",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = pd.read_excel('all_companies.xlsx', index_col=0)\n",
    "all_companies.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce6870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filings(CIK):\n",
    "    headers = {\n",
    "    'User-Agent': 'kuleuven amin.tavakkolnia@kuleuven.be'\n",
    "    }\n",
    "    res = make_request(f\"https://data.sec.gov/submissions/CIK{CIK:010d}.json\", headers=headers)\n",
    "    filings = res.json()['filings']\n",
    "    recent_files = filings['recent']\n",
    "    temp = pd.DataFrame(recent_files)\n",
    "    \n",
    "    if filings.get('files'):\n",
    "        add_files_name = filings['files'][0]['name']\n",
    "        add_files = make_request(f\"https://data.sec.gov/submissions/{add_files_name}\", headers=headers).json()\n",
    "        add_files_df = pd.DataFrame(add_files)\n",
    "\n",
    "        temp = pd.concat([temp, add_files_df])\n",
    "\n",
    "    temp[\"CIK\"] = CIK\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f2926a",
   "metadata": {},
   "source": [
    "https://www.sec.gov/Archives/edgar/data/1632053/000107997419000277/apotheca10k_1312019.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5469f191",
   "metadata": {},
   "outputs": [],
   "source": [
    "accessionNumber = '000110465906084288'\n",
    "doc_name = 'a06-25759_210k.htm'\n",
    "url = \"https://www.sec.gov/Archives/edgar/data/\" + str(CIK) + \"/\" + accessionNumber + \"/\" + doc_name\n",
    "\n",
    "report = make_request(url, max_retries=10)\n",
    "\n",
    "html = BeautifulSoup(report.content, 'html.parser')\n",
    "\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802bcd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "punc = set(string.punctuation)\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e65e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "filings_df = pd.read_csv(\"Data/filings_df.csv\")\n",
    "filings_df['url'] = (\n",
    "    \"https://www.sec.gov/Archives/edgar/data/\" + \n",
    "    filings_df[\"cik\"].astype(str) + \"/\" + \n",
    "    filings_df['accessionNumber'].str.replace('-', '') + \"/\" + \n",
    "    filings_df[\"primaryDocument\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7d9bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "'User-Agent': 'kuleuven amin.tavakkolnia'\n",
    "}\n",
    "res = make_request(filings_df['url'][0], max_retries=10, headers=headers)\n",
    "html = BeautifulSoup(res.content, 'html.parser')\n",
    "text = html.body.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4eab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length(url):\n",
    "\n",
    "    res = make_request(url=url, max_retries=10, headers=headers)\n",
    "    html = BeautifulSoup(res.content, 'html.parser')\n",
    "    text = html.body.text\n",
    "    \n",
    "    lower = text.lower()\n",
    "    alpha = ''.join(x for x in lower if x.isalpha() or x.isspace())\n",
    "    # punc_free = ''.join(x for x in num_free if x not in punc)\n",
    "    stop_free = [x for x in alpha.split() if x not in stop]\n",
    "\n",
    "    return len(stop_free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a631141",
   "metadata": {},
   "outputs": [],
   "source": [
    "filings_df['url'][:10].apply(get_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f405097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex to get \"Item 1A\"\n",
    "\n",
    "# item = 'Item 1A risk factors'.lower()\n",
    "# pattern = \"(item[\\-_\\s]?1a)?[\\s\\-_:]*(risk factor[s])?\"\n",
    "\n",
    "# re.fullmatch(pattern=pattern, string=item)\n",
    "\n",
    "# def find_risks(tag):\n",
    "#     pattern = \"(item[\\-_\\s]?1a[\\.]?)[\\s\\-_:]*(risk factor[s]?)\"\n",
    "#     if re.fullmatch(pattern=pattern, string=str(tag.string).lower()):\n",
    "#         return True\n",
    "#     else:\n",
    "#         return False\n",
    "    \n",
    "# tags = html.find_all(find_risks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1bb5b6",
   "metadata": {},
   "source": [
    "# SEC API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee2418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sec_api import QueryApi, ExtractorApi, MappingApi\n",
    "import html\n",
    "import gc\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import re\n",
    "\n",
    "extractorApi = ExtractorApi(\"355b10a7c3b55716e8d0ec69c6b24c724d99b050369b066d94fe94dce289b65e\")\n",
    "queryApi = QueryApi(api_key=\"355b10a7c3b55716e8d0ec69c6b24c724d99b050369b066d94fe94dce289b65e\")\n",
    "mappingApi = MappingApi(api_key='355b10a7c3b55716e8d0ec69c6b24c724d99b050369b066d94fe94dce289b65e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addae2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls10K_df = pd.read_csv(\"Data/10Kurls.csv\").dropna(subset=['linkToFilingDetails', 'periodOfReport'])\n",
    "urls10K_df['filerCIK'] = urls10K_df['linkToFilingDetails'].apply(lambda x: x.split('/')[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1c7422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "with open('SEC_api.o56288177', 'r') as f:\n",
    "    errors = f.read()\n",
    "\n",
    "missed_urls = re.findall(pattern=r\"https://[^\\s]*\\.(?:htm|txt)\", string=errors)\n",
    "\n",
    "urls10K_df = urls10K_df[urls10K_df['linkToFilingDetails'].isin(missed_urls)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c22e8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "  \"query\": { \"query_string\": { \n",
    "      \"query\": \"formType:\\\"13F-HR\\\" \" + \n",
    "               \"AND NOT formType:\\\"13F-HR/A\\\" \" +\n",
    "               \"AND filedAt:[2014-01-01 TO 2014-02-01]\",\n",
    "      \"time_zone\": \"America/New_York\"\n",
    "  } },\n",
    "  \"from\": \"0\",\n",
    "  \"size\": \"20\",\n",
    "  \"sort\": [{ \"filedAt\": { \"order\": \"desc\" } }]\n",
    "}\n",
    "\n",
    "response = queryApi.get_filings(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127d7754",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response['filings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8356dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Flatten_holdings(filing):\n",
    "    # Extract general data\n",
    "    general_data = dict([(key, filing.get(key)) for key in ['formType', 'cik', 'filedAt', 'periodOfReport']])\n",
    "\n",
    "    # Flatten holdings\n",
    "    flattened_holdings = []\n",
    "    for holding in filing['holdings']:\n",
    "        flat_holding = general_data.copy()\n",
    "        flat_holding.update({\n",
    "            'cusip': holding.get('cusip'),\n",
    "            'holding_cik': holding.get('cik'),\n",
    "            'otherManager': holding.get('otherManager'),\n",
    "            'investmentDiscretion': holding.get('investmentDiscretion'),\n",
    "            'value': holding.get('value'),\n",
    "            'titleOfClass': holding.get('titleOfClass')\n",
    "        })\n",
    "        flattened_holdings.append(flat_holding)\n",
    "\n",
    "    return flattened_holdings\n",
    "\n",
    "holdings_list = []\n",
    "\n",
    "for filing in response['filings']:\n",
    "    holdings_list.extend(Flatten_holdings(filing))\n",
    "\n",
    "holdings_df = pd.DataFrame(holdings_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0581316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls10K_df = pd.read_csv(\"Data/10Kurls.csv\").dropna(subset=['linkToFilingDetails', 'periodOfReport'])\n",
    "CIKs = urls10K_df['cik'].unique()\n",
    "\n",
    "def cik_tic_map(cik, retries=3):\n",
    "    \"\"\"\n",
    "    map CIK to ticker, CUSIP and company details \n",
    "    \"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            result = mappingApi.resolve('cik', str(cik))\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            time.sleep(5)\n",
    "            if attempt == retries - 1:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "output = [cik_tic_map(cik) for cik in CIKs[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f409c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cik_ticker_df = pd.DataFrame([x for X in output for x in X]).drop_duplicates(subset=['cik', 'ticker'])\n",
    "cik_ticker_df['cik'] = cik_ticker_df['cik'].astype(int)\n",
    "\n",
    "cik_ticker_df = cik_ticker_df[cik_ticker_df['cik'].isin(CIKs)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf00261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cik_ticker_df.to_csv('Data/CIK_Ticker_CUSIP.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b0fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_query = {\n",
    "  \"query\": { \n",
    "      \"query_string\": { \n",
    "          \"query\": \"PLACEHOLDER\", # this will be set during runtime \n",
    "          \"time_zone\": \"America/New_York\"\n",
    "      } \n",
    "  },\n",
    "  \"from\": \"0\", # starting point in the list of urls\n",
    "  \"size\": \"200\", # number of data points returned in every call\n",
    "  # sort by filedAt\n",
    "  \"sort\": [{ \"filedAt\": { \"order\": \"desc\" } }]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7975e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'NT 10-K' = Non-Timely 10-K - Not a annual report 10-K filing\n",
    "# '10-K/A' filing amendment\n",
    "universe_query = \"formType:\\\"10-K\\\" \" + \"AND NOT formType:\\\"NT 10-K\\\" \" + \"AND filedAt:[2022-01-01 TO 2022-01-31]\"\n",
    "base_query[\"query\"][\"query_string\"][\"query\"] = universe_query;\n",
    "response = queryApi.get_filings(base_query)\n",
    "\n",
    "urls_list = list(map(\n",
    "    lambda x: [x.get(key) for key in ['linkToFilingDetails', 'cik', 'ticker', \n",
    "                                      'filedAt', 'periodOfReport', 'formType']], \n",
    "    response[\"filings\"]\n",
    "))\n",
    "\n",
    "urls10K_df = pd.DataFrame(urls_list, columns=['linkToFilingDetails', 'cik', 'ticker', \n",
    "                                      'filedAt', 'periodOfReport', 'formType'])\n",
    "\n",
    "urls10K_df['filedAt'] = urls10K_df['filedAt'].apply(lambda x: x.split('T')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cdc4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_text = extractorApi.get_section(filing_url=urls10K_df['linkToFilingDetails'][0], section='1A', return_type='html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969d6e22",
   "metadata": {},
   "source": [
    "### Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88358c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all submissions\n",
    "submissions = glob.glob(\"Data\\submissions\\*\")\n",
    "\n",
    "firm_info = []\n",
    "for file in tqdm(submissions):\n",
    "    with open(file, 'rb') as f:\n",
    "        content = json.load(f)\n",
    "        try:\n",
    "            firm_info.append([content.get(key) for key in [\"cik\", \"entityType\", \"sic\", \"category\"]])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "firm_info_df = pd.DataFrame(\n",
    "    firm_info, \n",
    "    columns=[\"CIK\", \"entityType\", \"SIC\", \"category\"]\n",
    ")\n",
    "\n",
    "firm_info_df.to_csv(\"firm_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329a2872",
   "metadata": {},
   "outputs": [],
   "source": [
    "firm_info_df = pd.read_csv(\"firm_info.csv\")\n",
    "firm_info_df[\"CIK\"] = firm_info_df[\"CIK\"].astype(int)\n",
    "\n",
    "tickers = (\n",
    "    firm_info_df.set_index([\"CIK\", \"SIC\"])['tickers']\n",
    "    .str.strip('[]').str.replace(\"'\", \"\")\n",
    "    .replace(r'^\\s*$', np.nan, regex=True)\n",
    "    .str.split(\",\").dropna()\n",
    "    .explode()\n",
    ").reset_index()\n",
    "\n",
    "\"\"\"\n",
    "tik_txt = '\\n'.join(tickers.str.replace(\"\\s*'*[*]*\", \"\"))\n",
    "\n",
    "with open('tickers.txt', \"w\") as f:\n",
    "    f.write(tik_txt)\n",
    "\"\"\"\n",
    "\n",
    "tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429a1326",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = pd.read_csv(\"Data/all_files.csv\")\n",
    "CIKs = \"\\n\".join(all_files.CIK.astype(str).unique().tolist())\n",
    "with open('CIK.txt', \"w\") as f:\n",
    "    f.write(CIKs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f878b544",
   "metadata": {},
   "source": [
    "# EIKON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2caa5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75a56c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import refinitiv.data as rd\n",
    "# rd.open_session()\n",
    "\n",
    "# rd.close_session()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3f99148",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a52aead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filings_df = pd.read_csv(\"Data\\clean_docs_3.csv\", index_col=0)\n",
    "T2V_df = pd.read_csv(\n",
    "    filepath_or_buffer=\"Top2Vec/T2V_df_5.csv\", \n",
    "    parse_dates=['Report_dt', 'Filing_dt'], \n",
    "    usecols=['CIK', 'Report_dt', 'Filing_dt']\n",
    ").rename(columns={'Report_dt': 'report_dt', 'Filing_dt': 'filing_dt'}).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f33d8c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "T2V_df = T2V_df[(T2V_df['report_dt']>'2006-01-01')&(T2V_df['report_dt']<'2024-01-01')]\n",
    "obs_df = T2V_df.groupby(\"CIK\").agg({\"report_dt\": \"min\", \"filing_dt\": \"max\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c39f2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs_df = T2V_df[[\"CIK\", \"filing_dt\"]].groupby(\"CIK\")['filing_dt'].agg([\"min\", 'max']).reset_index()\n",
    "# obs_df[\"SDate\"] = (\n",
    "#     obs_df[\"min\"].dt.date - relativedelta(months=6)\n",
    "#     ).astype(str)\n",
    "\n",
    "# obs_df[\"EDate\"] = (\n",
    "#     obs_df[\"max\"].dt.date + relativedelta(months=6)\n",
    "#     ).astype(str)\n",
    "    \n",
    "obs_df[\"SDate\"] = obs_df[\"report_dt\"].dt.date.astype(str)\n",
    "\n",
    "obs_df[\"EDate\"] = obs_df[\"filing_dt\"].dt.date.astype(str)\n",
    "\n",
    "obs_df[\"CIK\"] = obs_df[\"CIK\"].apply(lambda cik: f\"{cik:010d}\")\n",
    "\n",
    "obs = obs_df.to_records()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a88615ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eikon as ek\n",
    "# ek.set_app_key('f85c7bd3ede24dae99baad798c810fed013b9769') #1\n",
    "ek.set_app_key('916a59e4580e4d908d2318335926c91a4a1b1851') #2\n",
    "# ek.set_app_key('9f63922b6e2f465393b927960fd87954bc4a73d8') #3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fca48da5",
   "metadata": {},
   "source": [
    "### Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f7a918",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for o in tqdm(np.array_split(obs, 500)[:50]):\n",
    "    SDate = o[\"SDate\"].min()\n",
    "    EDate = o[\"EDate\"].max()\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            df = rd.get_data(\n",
    "                universe=o[\"CIK\"].tolist(), \n",
    "                fields = [\n",
    "                    'TR.CLOSEPRICE(Adjusted=1)',\n",
    "                    'TR.CLOSEPRICE.date',\n",
    "                    'TR.OPENPRICE(Adjusted=1)',\n",
    "                    # 'TR.OPENPRICE.date',\n",
    "                    # 'TR.PRICECLOSE',\n",
    "                    # 'TR.PRICECLOSEDATE', \n",
    "                    'TR.Volume',\n",
    "                    'TR.Volume.date',\n",
    "                    # 'TR.TtlCmnSharesOut(Period=FQ0)',\n",
    "                    # 'TR.TtlCmnSharesOut(Period=FQ0).date'\n",
    "                ], \n",
    "                parameters={'SDate': SDate, 'EDate': EDate},\n",
    "                # use_field_names_in_headers=True\n",
    "            )\n",
    "            if df is not None:\n",
    "                data.append(df.dropna(subset=['Date'], how='all').drop_duplicates())\n",
    "        \n",
    "            gc.collect()\n",
    "            break\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"E: {e}\")\n",
    "            time.sleep(5)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cabea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157dd66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd.close_session()\n",
    "data.to_csv(\"Data\\EIKON_prices.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831522c2",
   "metadata": {},
   "source": [
    "### Free Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45bd020",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for o in tqdm(np.array_split(obs, 500)):\n",
    "    SDate = o[\"SDate\"].min()\n",
    "    EDate = o[\"EDate\"].max()\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            df = rd.get_data(\n",
    "                universe=o[\"CIK\"].tolist(), \n",
    "                fields = [\n",
    "                    'TR.SharesFreeFloat',\n",
    "                    'TR.SharesFreeFloat.date',\n",
    "                    'TR.FreeFloat',\n",
    "                    'TR.FreeFloat.date'\n",
    "                ], \n",
    "                parameters={'SDate': SDate, 'EDate': EDate},\n",
    "            )\n",
    "\n",
    "            if df is not None:\n",
    "                data.append(df.dropna(subset=['Date'], how='all').drop_duplicates())\n",
    "        \n",
    "            gc.collect()\n",
    "            break\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"E: {e}\")\n",
    "            time.sleep(5)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9473bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"Data\\EIKON_FreeFloat.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4110fed6",
   "metadata": {},
   "source": [
    "### Bid-Ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1dd252",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "for o in tqdm(obs):\n",
    "    SDate = o[\"SDate\"]\n",
    "    EDate = o[\"EDate\"]\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            df, err = ek.get_data(\n",
    "                instruments=o[\"CIK\"], \n",
    "                fields = [\n",
    "                    'TR.HIGHPRICE(Adjusted=1)',\n",
    "                    'TR.HIGHPRICE.date',\n",
    "                    'TR.LOWPRICE(Adjusted=1)',\n",
    "                    'TR.LOWPRICE.date',\n",
    "                    'TR.BIDPRICE(Adjusted=1)',\n",
    "                    'TR.BIDPRICE.date',\n",
    "                    'TR.ASKPRICE(Adjusted=1)',\n",
    "                    'TR.ASKPRICE.date'\n",
    "                ], \n",
    "                parameters={'SDate': SDate, 'EDate': EDate},\n",
    "                field_name=True\n",
    "            )\n",
    "            if not err:\n",
    "                data = pd.concat([data, df])\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(20)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5574a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"Data\\EIKON_bidask.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee39d878",
   "metadata": {},
   "source": [
    "### Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43b1f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "for o in tqdm(obs):\n",
    "    SDate = o[\"SDate\"]\n",
    "    EDate = o[\"EDate\"]\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            df, err = ek.get_data(\n",
    "                instruments=o[\"CIK\"], \n",
    "                fields = [\n",
    "                    'TR.WACCBeta',\n",
    "                    'TR.WACCBeta.date',\n",
    "                    'TR.BetaDaily180D',\n",
    "                    'TR.BetaDaily180D.date',\n",
    "                    'TR.BetaDaily90D',\n",
    "                    'TR.BetaDaily90D.date',\n",
    "                    'TR.WACC',\n",
    "                    'TR.WACC.date',\n",
    "                ], \n",
    "                parameters={'SDate': SDate, 'EDate': EDate},\n",
    "                field_name=True\n",
    "            )\n",
    "            if not err:\n",
    "                data = pd.concat([data, df])\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(30)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27067f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"Data\\EIKON_beta.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ebcc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ek.get_data)\n",
    "ek.get_symbology(\"MSFC\", from_symbol_type='ticker', to_symbol_type=['RIC', 'ISIN'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1309f8c",
   "metadata": {},
   "source": [
    "### Analysts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35328337",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for o in tqdm(np.array_split(obs, 500)):\n",
    "    SDate = o[\"SDate\"].min()\n",
    "    EDate = o[\"EDate\"].max()\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            df, err = ek.get_data(\n",
    "                instruments=o[\"CIK\"].tolist(), \n",
    "                fields = [\n",
    "                    'TR.NumberOfAnalysts',\n",
    "                    'TR.NumberOfAnalysts.date',\n",
    "                    # 'TR.ARMIntraCountryScore',\n",
    "                    # 'TR.ARMIntraIndustryScore',\n",
    "                    # 'TR.SIInstitutionalOwn',\n",
    "                ], \n",
    "                parameters={'SDate': SDate, 'EDate': EDate},\n",
    "                field_name=True\n",
    "            )\n",
    "            \n",
    "            if df is not None:\n",
    "                data.append(df.drop_duplicates())\n",
    "\n",
    "                gc.collect()\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"E: {e}\")\n",
    "            time.sleep(1)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b259d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.concat(data)\n",
    "data_df.columns = ['Instrument', 'NUMBEROFANALYSTS', 'Date', 'None']\n",
    "data_df.drop(columns=\"None\", inplace=True)\n",
    "data_df['Date'] = pd.to_datetime(data_df['Date'], errors='coerce').dt.tz_localize(None)\n",
    "data_df.dropna(subset=['Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a179bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c58fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv(\"Data/Analysts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4515894e",
   "metadata": {},
   "source": [
    "### Financials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f852471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "for o in tqdm(np.array_split(obs, 200)):\n",
    "    SDate = o[\"SDate\"].min()\n",
    "    EDate = o[\"EDate\"].max()\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            df, err = ek.get_data(\n",
    "                instruments=o[\"CIK\"].tolist(), \n",
    "                fields = [\n",
    "                    'TR.TotalAssetsReported(Period=FY0).date',\n",
    "                    'TR.TotalAssetsReported(Period=FY0)',\n",
    "                    'TR.TotalDebtOutstanding(Period=FY0).date',\n",
    "                    'TR.TotalDebtOutstanding(Period=FY0)',\n",
    "                    'TR.NetIncome(Period=FY0).date',\n",
    "                    'TR.NetIncome(Period=FY0)',\n",
    "                    'TR.TotalRevenue(Period=FY0).date',\n",
    "                    'TR.TotalRevenue(Period=FY0)',\n",
    "                    'TR.TotalEquity(Period=FY0).date',\n",
    "                    'TR.TotalEquity(Period=FY0)',\n",
    "                    'TR.IntangiblesNet(Period=FY0).date',\n",
    "                    'TR.IntangiblesNet(Period=FY0)',\n",
    "                    'TR.ResearchAndDevelopment(Period=FY0).date',\n",
    "                    'TR.ResearchAndDevelopment(Period=FY0)',\n",
    "                    'TR.TotalOperatingExpense(Period=FY0).date',\n",
    "                    'TR.TotalOperatingExpense(Period=FY0)',\n",
    "                    'TR.OperatingExpActual(Period=FY0).date',\n",
    "                    'TR.OperatingExpActual(Period=FY0)',\n",
    "                    'TR.TotalCurrentAssets(Period=FY0).date',\n",
    "                    'TR.TotalCurrentAssets(Period=FY0)',\n",
    "                    'TR.TotalCurrLiabilities(Period=FY0).date',\n",
    "                    'TR.TotalCurrLiabilities(Period=FY0)',\n",
    "                ], \n",
    "                parameters={'SDate': SDate, 'EDate': EDate},\n",
    "                field_name=True\n",
    "            )\n",
    "            \n",
    "            data = pd.concat([data, df.drop_duplicates()])\n",
    "            break\n",
    "\n",
    "        except:\n",
    "            time.sleep(20)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4de3284",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates().to_csv(\"Data\\EIKON_Financials.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efe26b9",
   "metadata": {},
   "source": [
    "### Earnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ce2746",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "# for yr in range(2007, 2024):\n",
    "for yr in range(2007, 2010):\n",
    "# for yr in range(2013, 2019):\n",
    "# for yr in range(2019, 2024):\n",
    "    print(yr)\n",
    "    for o in tqdm(np.array_split(obs, 200)):\n",
    "        o = o[(o['SDate']<f\"{yr}-01-01\")&(o['EDate']>f\"{yr}-12-31\")]\n",
    "        while True:\n",
    "            try:\n",
    "                df, err = ek.get_data(\n",
    "                    instruments=o[\"CIK\"].tolist(), \n",
    "                    fields = [\n",
    "                            'TR.EPSEstValue().date',\n",
    "                            'TR.EPSEstValue().periodenddate',\n",
    "                            'TR.EPSEstValue().analystcode',\n",
    "                            'TR.EPSEstValue()',\n",
    "                        ], \n",
    "                        parameters={'SDate': f\"FY{yr-1}\", 'EDate': f'FY{yr}', 'Period': f'FY{yr}'},\n",
    "                        field_name=True\n",
    "                    )\n",
    "                    \n",
    "                if df is not None:\n",
    "                    data.append(df.dropna(subset='TR.EPSESTVALUE()').drop_duplicates())\n",
    "\n",
    "                    gc.collect()\n",
    "                    break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"E: {e}\")\n",
    "                time.sleep(1)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67459b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1872dcb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instrument</th>\n",
       "      <th>TR.EPSESTVALUE().DATE</th>\n",
       "      <th>TR.EPSESTVALUE().periodenddate</th>\n",
       "      <th>TR.EPSESTVALUE().analystcode</th>\n",
       "      <th>TR.EPSESTVALUE()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1750</td>\n",
       "      <td>2006-02-15T17:20:00Z</td>\n",
       "      <td>2007-05-31</td>\n",
       "      <td>3VBW</td>\n",
       "      <td>1.39895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1750</td>\n",
       "      <td>2006-03-17T14:21:00Z</td>\n",
       "      <td>2007-05-31</td>\n",
       "      <td>3PTB</td>\n",
       "      <td>1.61879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1750</td>\n",
       "      <td>2006-03-20T18:11:00Z</td>\n",
       "      <td>2007-05-31</td>\n",
       "      <td>11ZW</td>\n",
       "      <td>1.39895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1750</td>\n",
       "      <td>2006-06-12T16:11:00Z</td>\n",
       "      <td>2007-05-31</td>\n",
       "      <td>51BZ</td>\n",
       "      <td>1.34899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1750</td>\n",
       "      <td>2006-07-13T08:29:00Z</td>\n",
       "      <td>2007-05-31</td>\n",
       "      <td>51BZ</td>\n",
       "      <td>1.39895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>1382696</td>\n",
       "      <td>2007-12-03T07:25:00Z</td>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>2XLX</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>1382696</td>\n",
       "      <td>2007-12-03T08:41:00Z</td>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>42AG</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>1382696</td>\n",
       "      <td>2007-12-13T07:18:00Z</td>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>2XLX</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>1382696</td>\n",
       "      <td>2008-02-21T12:29:00Z</td>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>2XLX</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>1382696</td>\n",
       "      <td>2008-03-27T08:24:00Z</td>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>42AG</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94102 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Instrument TR.EPSESTVALUE().DATE TR.EPSESTVALUE().periodenddate  \\\n",
       "2           1750  2006-02-15T17:20:00Z                     2007-05-31   \n",
       "1           1750  2006-03-17T14:21:00Z                     2007-05-31   \n",
       "4           1750  2006-03-20T18:11:00Z                     2007-05-31   \n",
       "5           1750  2006-06-12T16:11:00Z                     2007-05-31   \n",
       "10          1750  2006-07-13T08:29:00Z                     2007-05-31   \n",
       "...          ...                   ...                            ...   \n",
       "1705     1382696  2007-12-03T07:25:00Z                     2007-12-31   \n",
       "1704     1382696  2007-12-03T08:41:00Z                     2007-12-31   \n",
       "1721     1382696  2007-12-13T07:18:00Z                     2007-12-31   \n",
       "1812     1382696  2008-02-21T12:29:00Z                     2007-12-31   \n",
       "1860     1382696  2008-03-27T08:24:00Z                     2007-12-31   \n",
       "\n",
       "     TR.EPSESTVALUE().analystcode  TR.EPSESTVALUE()  \n",
       "2                            3VBW           1.39895  \n",
       "1                            3PTB           1.61879  \n",
       "4                            11ZW           1.39895  \n",
       "5                            51BZ           1.34899  \n",
       "10                           51BZ           1.39895  \n",
       "...                           ...               ...  \n",
       "1705                         2XLX              0.63  \n",
       "1704                         42AG              0.65  \n",
       "1721                         2XLX              0.66  \n",
       "1812                         2XLX              0.67  \n",
       "1860                         42AG              0.69  \n",
       "\n",
       "[94102 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90807146",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.concat(data)\n",
    "\n",
    "data_df.dropna(subset=['TR.EPSESTVALUE().DATE', 'TR.EPSESTVALUE()'], inplace=True)\n",
    "\n",
    "data_df = data_df.sort_values(['Instrument', 'TR.EPSESTVALUE().DATE', 'TR.EPSESTVALUE().periodenddate'])\\\n",
    "    .drop_duplicates(['Instrument', 'TR.EPSESTVALUE().periodenddate', \n",
    "                      'TR.EPSESTVALUE().analystcode', 'TR.EPSESTVALUE()'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bc4854",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv(\"Data\\EIKON_EPSforecast.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a602b83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for o in tqdm(np.array_split(obs, 300)):\n",
    "    SDate = o[\"SDate\"].min()\n",
    "    EDate = o[\"EDate\"].max()\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            df, err = ek.get_data(\n",
    "                instruments=o[\"CIK\"].tolist(), \n",
    "                fields = [\n",
    "                    \"TR.EPSActValue.date\",\n",
    "                    'TR.EPSActValue.announcedate',\n",
    "                    'TR.EPSActValue.periodenddate',\n",
    "                    'TR.EPSActValue'\n",
    "                ], \n",
    "                parameters={'SDate': SDate, 'EDate': EDate},\n",
    "                field_name=True\n",
    "            )\n",
    "            \n",
    "            if df is not None:\n",
    "                data.append(df.drop_duplicates())\n",
    "\n",
    "                gc.collect()\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"E: {e}\")\n",
    "            time.sleep(1)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121ff24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.concat(data)\n",
    "\n",
    "data_df = data_df.drop_duplicates().sort_values(['Instrument', 'Date']).reset_index(drop=True)\n",
    "\n",
    "data_df['Date'] = data_df['Date'].dt.date\n",
    "data_df['Report Date'] = data_df['Report Date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980f502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd.close_session()\n",
    "data_df.to_csv(\"Data\\EIKON_EPSActual.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f97ab80",
   "metadata": {},
   "source": [
    "### Ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544d03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for o in tqdm(np.array_split(obs, 400)):\n",
    "    SDate = o[\"SDate\"].min()\n",
    "    EDate = o[\"EDate\"].max()\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            df, err = ek.get_data(\n",
    "                instruments=o[\"CIK\"].tolist(), \n",
    "                fields = [\n",
    "                    'TR.CategoryOwnershipPct().date',\n",
    "                    'TR.CategoryOwnershipPct().categoryvalue',\n",
    "                    'TR.CategoryOwnershipPct()',\n",
    "                ], \n",
    "                parameters={'SDate': SDate, 'EDate': EDate, 'StatType': '1'},\n",
    "                field_name=True\n",
    "            )\n",
    "            \n",
    "            if df is not None:\n",
    "                data.append(df.drop_duplicates())\n",
    "\n",
    "                gc.collect()\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"E: {e}\")\n",
    "            time.sleep(1)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca1b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.concat(data)\n",
    "data_df.columns = ['Instrument', 'Date', 'Category Value', 'Percent Of Traded Share']\n",
    "data_df['Date'] = pd.to_datetime(data_df['Date'], errors='coerce').dt.tz_localize(None)\n",
    "data_df.dropna(subset=['Date'], inplace=True)\n",
    "data_df = data_df.drop_duplicates().sort_values(['Instrument', 'Date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb23266",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv(\"Data\\EIKON_Ownership1.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7fd3ade",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009098bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import liberaries and functions\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78a28a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Owner = []\n",
    "for i in [1,4]:\n",
    "    Owner.append(pd.read_csv(f\"Data\\EIKON_Ownership{i}.csv\", parse_dates=['Date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee88202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Owner = pd.concat(Owner).dropna().groupby(['Instrument', 'Date', 'Category Value']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb57c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Owner['Category Value'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abae5a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "Owner.to_csv(\"Data\\EIKON_Ownership.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee1097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = []\n",
    "for i in [1,2,3,4,5]:\n",
    "    EPS.append(pd.read_csv(\n",
    "        f\"Data\\EIKON_EPSforecast{i}.csv\", header=0, \n",
    "               parse_dates=['Date', 'Period End Date']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc5c834",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0,1,2,3,4]:\n",
    "    EPS[i]['Date'] = EPS[i]['Date'].dt.date\n",
    "\n",
    "EPS = pd.concat(EPS).drop_duplicates()\n",
    "\n",
    "EPS = EPS.sort_values(['Instrument', 'Date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff96537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(f\"Data\\EIKON_EPSforecast(1).csv\", header=0, parse_dates=['Date', 'Period End Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a8824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(f\"Data\\EIKON_EPSforecast(2).csv\", header=0, parse_dates=['Date', 'Period End Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62524658",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(columns=\"Calc Date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6693ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = pd.concat([df1,df2]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a738dc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS.to_csv(\"Data\\EIKON_EPSforecast.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e3eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "financials = pd.read_csv(\"Data\\EIKON_Financials.csv\")\n",
    "financials.drop_duplicates(inplace=True)\n",
    "financials.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2086ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NAs\n",
    "financials = financials.drop(columns=['0']).dropna(subset=[\"Instrument\"])\n",
    "\n",
    "financials.dropna(\n",
    "    subset=financials.columns[1:], how='all', inplace=True)\n",
    "\n",
    "financials[\"Instrument\"] = financials[\"Instrument\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dd068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = financials.columns[1::2]\n",
    "values = financials.columns[2::2]\n",
    "\n",
    "dfs = [(\n",
    "    financials[['Instrument', a, b]]\n",
    "    .dropna(subset=[a, b])\n",
    "    .drop_duplicates()\n",
    "    .set_index(['Instrument', a])\n",
    ") for a, b in zip(dates, values)]\n",
    "\n",
    "financials_df = pd.concat(dfs, axis=1).reset_index()\n",
    "financials_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed21d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "financials_df.fillna({\"TR.TOTALOPERATINGEXPENSE(PERIOD=FY0)\": financials_df[\"TR.OPERATINGEXPACTUAL(PERIOD=FY0)\"]}, inplace=True)\n",
    "financials_df = financials_df.drop(columns='TR.OPERATINGEXPACTUAL(PERIOD=FY0)').rename(columns={'level_1': 'Date'}).drop_duplicates()\n",
    "financials_df.to_csv(\"Data\\Financials2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79962f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysts = pd.read_csv(\"Data\\Analysts.csv\")\n",
    "analysts.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2534ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "FreeFloat = pd.read_csv(\"Data\\EIKON_FreeFloat.csv\")\n",
    "FreeFloat.drop_duplicates(inplace=True)\n",
    "FreeFloat.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bfaaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NAs\n",
    "FreeFloat = FreeFloat.drop(columns=['0']).dropna(subset=[\"Instrument\"])\n",
    "\n",
    "FreeFloat.dropna(\n",
    "    subset=['TR.SHARESFREEFLOAT', 'TR.SHARESFREEFLOAT.DATE',\n",
    "            'TR.FREEFLOAT', 'TR.FREEFLOAT.DATE'], how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646ac12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = FreeFloat.columns[2::2]\n",
    "values = FreeFloat.columns[1::2]\n",
    "\n",
    "dfs = [(\n",
    "    FreeFloat[['Instrument', a, b]]\n",
    "    .dropna(subset=[a])\n",
    "    .drop_duplicates()\n",
    "    .set_index(['Instrument', a])\n",
    ") for a, b in zip(dates, values)]\n",
    "\n",
    "FreeFloat_df = pd.concat(dfs, axis=1).reset_index()\n",
    "FreeFloat_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fdb50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FreeFloat_df[\"TR.SHARESFREEFLOAT\"].fillna(FreeFloat_df[\"TR.FREEFLOAT\"], inplace=True)\n",
    "FreeFloat_df = FreeFloat_df.drop(columns='TR.FREEFLOAT').rename(columns={'level_1': 'Date'}).drop_duplicates()\n",
    "FreeFloat_df.to_csv(\"Data\\FreeFloat.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7352fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = pd.read_csv(\"Data\\EIKON_prices.csv\")\n",
    "prices.drop_duplicates(inplace=True)\n",
    "prices.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e151b201",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = prices.columns[2::2]\n",
    "values = prices.columns[1::2]\n",
    "\n",
    "dfs = [(\n",
    "    prices[['Instrument', a, b]]\n",
    "    .dropna(subset=[a])\n",
    "    .drop_duplicates()\n",
    "    .set_index(['Instrument', a])\n",
    ") for a, b in zip(dates, values)]\n",
    "\n",
    "# Handling duplicates for shares outstanding\n",
    "dfs[5] = dfs[5][\n",
    "    ~(dfs[5].index.duplicated(keep=False))&(dfs[5]['TR.TTLCMNSHARESOUT(PERIOD=FQ0)'].notna())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c87801",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_df = pd.concat(dfs, axis=1).reset_index()\n",
    "\n",
    "del prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c35fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_df['Date'] = pd.to_datetime(prices_df[\"level_1\"]).dt.tz_localize(None)\n",
    "prices_df.drop(columns=['level_1'], inplace=True)\n",
    "\n",
    "prices_df.columns = [\n",
    "    'Instrument', 'CLOSEPRICE', 'OPENPRICE', 'PRICECLOSE', 'VOLUME', \n",
    "    'COMPANYMARKETCAP', 'TTLCMNSHARESOUT', 'Date'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748eedeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing missing close prices with the open price of the same day\n",
    "prices_df[\"CLOSEPRICE\"].fillna(prices_df['PRICECLOSE'], inplace=True)\n",
    "prices_df[\"CLOSEPRICE\"].fillna(prices_df[\"OPENPRICE\"], inplace=True)\n",
    "\n",
    "prices_df.drop(columns=['OPENPRICE', 'PRICECLOSE'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e262ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing missing TTLCMNSHARESOUT with previouse values\n",
    "prices_df[\"TTLCMNSHARESOUT\"] = prices_df.groupby([\"Instrument\"])[\"TTLCMNSHARESOUT\"].fillna(method='ffill')\n",
    "prices_df[\"TTLCMNSHARESOUT\"] = prices_df.groupby([\"Instrument\"])[\"TTLCMNSHARESOUT\"].fillna(method='bfill')\n",
    "\n",
    "prices_df[\"VOLUME\"].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c58a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad34a70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_df.to_csv(\"Data\\Prices.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f72f367",
   "metadata": {},
   "outputs": [],
   "source": [
    "BidAsk = pd.read_csv(\"Data\\EIKON_bidask.csv\").drop_duplicates()\n",
    "BidAsk.drop_duplicates(inplace=True)\n",
    "BidAsk.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30cdecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = BidAsk.columns[2::2]\n",
    "values = BidAsk.columns[1::2]\n",
    "\n",
    "dfs = [(\n",
    "    BidAsk[['Instrument', a, b]]\n",
    "    .dropna(subset=[a])\n",
    "    .drop_duplicates()\n",
    "    .set_index(['Instrument', a])\n",
    ") for a, b in zip(dates, values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44346534",
   "metadata": {},
   "outputs": [],
   "source": [
    "BidAsk_df = pd.concat(dfs, axis=1).reset_index()\n",
    "\n",
    "del BidAsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791e5f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "BidAsk_df['Date'] = pd.to_datetime(BidAsk_df[\"level_1\"]).dt.tz_localize(None)\n",
    "BidAsk_df.drop(columns=['level_1'], inplace=True)\n",
    "\n",
    "BidAsk_df.columns = [\n",
    "    'Instrument', 'HIGHPRICE', 'LOWPRICE', 'BIDPRICE', 'ASKPRICE', 'Date'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf59070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values\n",
    "BidAsk_df[\"BIDPRICE\"].fillna(BidAsk_df[\"LOWPRICE\"], inplace=True)\n",
    "BidAsk_df[\"ASKPRICE\"].fillna(BidAsk_df[\"HIGHPRICE\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de6a6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BidAsk_df.to_csv(\"Data\\BidAsk.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f3ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"TR.ARMIntraGlobalScore\"\n",
    "\"TR.NumberOfAnalysts(Period=FY1)\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ETM_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "2e814d5f901f2e2f1812217256e7a2386c6b3dac449e52472436b21a420d1617"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
