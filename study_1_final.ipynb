{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import liberaries and functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# plt.style.use('seaborn')\n",
    "# plt.rc('figure', autolayout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data sample \n",
    "RF_df = pd.read_csv(\"Data\\clean_docs_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1245475, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Top2Vec topics df\n",
    "t2v_df = (\n",
    "    pd.read_csv(\"Top2Vec\\T2V_df_H95.csv\")\n",
    "    .set_index(\"index\").drop(columns=['Docs'])\n",
    ")\n",
    "\n",
    "t2v_df.rename(columns={'Report_dt': 'report_dt', 'Filing_dt': 'filing_dt'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df = pd.concat([RF_df, t2v_df[['Topic', 'Score', 'Topic_H', 'Score_H']]], axis=1)\n",
    "\n",
    "topics_df[\"filing_dt\"] = pd.to_datetime(topics_df[\"filing_dt\"])\n",
    "topics_df[\"report_dt\"] = pd.to_datetime(topics_df[\"report_dt\"])\n",
    "\n",
    "topics_df['rprt_length'] = topics_df['cleaned_txt'].map(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Removing observations with duplicated filing_dt and ryear\n",
    "# sample = (\n",
    "#     topics_df[[\"CIK\", \"filing_dt\", \"report_dt\"]]\n",
    "#     .drop_duplicates()\n",
    "#     .sort_values([\"CIK\", \"filing_dt\", \"report_dt\"])\n",
    "# )\n",
    "\n",
    "# sample.drop_duplicates([\"CIK\", \"filing_dt\"], keep='last', inplace=True)\n",
    "\n",
    "# sample['ryear'] = sample['report_dt'].dt.year\n",
    "# sample.drop_duplicates([\"CIK\", \"ryear\"], keep='first', inplace=True)\n",
    "\n",
    "# sample.drop(columns='ryear', inplace=True)\n",
    "\n",
    "# topics_df = (\n",
    "#     topics_df.set_index([\"CIK\", \"filing_dt\", \"report_dt\"])\n",
    "#     .loc[sample.apply(lambda x: (x[0], x[1], x[2]), axis=1).values]\n",
    "#     .reset_index()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use historical SIC data for industry analysis\n",
    "sich = pd.read_csv(\n",
    "    filepath_or_buffer=\"Data\\Financials.csv\",\n",
    "    decimal=\".\", \n",
    "    thousands=',',\n",
    "    usecols=[\n",
    "        'cik', 'datadate', 'sich'\n",
    "    ]\n",
    ").drop_duplicates()\n",
    "\n",
    "sich.sort_values(['cik', 'datadate'], inplace=True)\n",
    "sich[\"datadate\"] = pd.to_datetime(sich[\"datadate\"], format=\"%d/%m/%Y\")\n",
    "\n",
    "topics_df = pd.merge(\n",
    "    left=topics_df,\n",
    "    right=sich[[\n",
    "        'cik', 'datadate', 'sich']],\n",
    "    left_on=[\"CIK\", \"report_dt\"],\n",
    "    right_on=[\"cik\", \"datadate\"],\n",
    "    how=\"left\"\n",
    ").drop(columns=['datadate', 'cik'])\n",
    "\n",
    "topics_df['sich'] = topics_df['sich'].fillna(topics_df['SIC']).astype(int)\n",
    "\n",
    "# First 2 digits of SIC -> Major sector group\n",
    "topics_df['sich'] = topics_df['SIC'].map(lambda x: f\"{int(x):04d}\"[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the records at the CIK-year level\n",
    "agg_tops = (\n",
    "    topics_df.groupby([\"CIK\", \"report_dt\", \"filing_dt\"])[\n",
    "        ['Topic', 'Topic_H', 'rprt_length', 'SIC', 'sich', 'Industry', 'category']\n",
    "    ]\n",
    "    .agg({\n",
    "        # 'filing_dt': 'max', \n",
    "        'Topic': lambda l: set(l), \n",
    "        'Topic_H': lambda l: set(l), \n",
    "        'rprt_length': 'sum',\n",
    "        'SIC' : 'unique', \n",
    "        'sich' : 'unique', \n",
    "        'Industry' : 'unique',\n",
    "        'category' : 'unique'\n",
    "    }).reset_index()\n",
    ").drop_duplicates(subset=[\"CIK\", \"filing_dt\", \"report_dt\"]).sort_values([\"CIK\", \"report_dt\", \"filing_dt\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_tops[\"SIC\"] = agg_tops[\"SIC\"].map(lambda x: x[0])\n",
    "agg_tops[\"sich\"] = agg_tops[\"sich\"].map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables for H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift records to compare every year with previous year\n",
    "agg_tops[\"shifted\"] = agg_tops.groupby(\"CIK\")['Topic'].shift(1)\n",
    "\n",
    "agg_tops.dropna(inplace=True)\n",
    "\n",
    "# Generate repeated, added and removed RFs\n",
    "agg_tops[\"repeated\"] = agg_tops.apply(lambda r: r['Topic'].intersection(r['shifted']), axis=1)\n",
    "agg_tops[\"added\"] = agg_tops.apply(lambda r: r['Topic'].difference(r['shifted']), axis=1)\n",
    "agg_tops[\"removed\"] = agg_tops.apply(lambda r: r['shifted'].difference(r['Topic']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_data = agg_tops[[\n",
    "    'CIK', 'filing_dt', 'report_dt', 'rprt_length', 'SIC', 'Industry', 'category'\n",
    "]].copy()\n",
    "\n",
    "# For individual topics\n",
    "stat_data[\"reported_crnt\"] = agg_tops['Topic'].map(len)\n",
    "stat_data[\"reported_last\"] = agg_tops['shifted'].map(len)\n",
    "stat_data[\"repeated\"] = agg_tops[\"repeated\"].map(len)\n",
    "stat_data[\"added\"] = agg_tops[\"added\"].map(len)\n",
    "stat_data[\"removed\"] = agg_tops[\"removed\"].map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_data['rfGap'] = (stat_data['filing_dt'] - stat_data['report_dt']).dt.days\n",
    "\n",
    "stat_data['fyear'] = stat_data['filing_dt'].dt.year\n",
    "stat_data['ryear'] = stat_data['report_dt'].dt.year"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables for H2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk topics disclosed and not disclosed per report \n",
    "disc_df = pd.pivot_table(\n",
    "    topics_df, index = [\"CIK\", \"filing_dt\", \"report_dt\", \"sich\"], \n",
    "    columns='Topic_H', values='Score_H'\n",
    ").notna().astype(int).reset_index()\n",
    "\n",
    "# disc_df[\"fyear\"] = disc_df[\"filing_dt\"].dt.year\n",
    "\n",
    "disc_df.sort_values(['CIK', 'report_dt', 'filing_dt'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between disclosed risk topics in 2 consecutive years\n",
    "disc_diff = disc_df.filter(range(0,100)) - disc_df.groupby(\"CIK\")[disc_df.filter(range(0,100)).columns].shift(1)\n",
    "\n",
    "disc_repeat = (\n",
    "    disc_df.filter(range(0,100))\n",
    "    + disc_df.groupby(\"CIK\")[disc_df.filter(range(0,100)).columns].shift(1) \n",
    "    == 2\n",
    ").astype(int)\n",
    "\n",
    "no_disc = -(disc_df.filter(range(0,100))-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To what extent the risk factors disclosed by the firm \n",
    "# are already disclosed by other firms over the past 52 weeks\n",
    "# Number of disclosing firms before the focal firm during the 52 weeks before filing date\n",
    "def count_func(x):\n",
    "    df_slice = disc_df[\n",
    "        (disc_df[\"filing_dt\"]>x[\"filing_dt\"] - pd.Timedelta(weeks=52))&\n",
    "        (disc_df[\"filing_dt\"]<x[\"filing_dt\"])&\n",
    "        (disc_df['CIK']!=x['CIK'])\n",
    "    ]\n",
    "    output = (df_slice.filter(range(0,100)).sum() + 1) / (df_slice[\"CIK\"].count() + 1)\n",
    "    \n",
    "    return output\n",
    "\n",
    "count_disc = disc_df.apply(count_func, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No. disclosing firms in the same industry devided by no. disclosing firms \n",
    "def count_func_ind(x):\n",
    "    df_slice = disc_df[\n",
    "        (disc_df[\"filing_dt\"]>x[\"filing_dt\"] - pd.Timedelta(weeks=52))&\n",
    "        (disc_df[\"filing_dt\"]<x[\"filing_dt\"])&\n",
    "        (disc_df['sich']==x['sich'])&\n",
    "        (disc_df['CIK']!=x['CIK'])\n",
    "    ]\n",
    "\n",
    "    output = (df_slice.filter(range(0,100)).sum() + 1) / (df_slice[\"CIK\"].count() + 1)\n",
    "\n",
    "    return output\n",
    "\n",
    "count_disc_ind = disc_df.apply(count_func_ind, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted disclosures\n",
    "disc_diff_w = disc_diff.multiply(count_disc.values)\n",
    "disc_w = disc_df.filter(range(0,101)).multiply(count_disc.values)\n",
    "disc_repeat_w = disc_repeat.multiply(count_disc.values)\n",
    "no_disc_w = no_disc.multiply(count_disc.values)\n",
    "\n",
    "disc_diff_w_ind = disc_diff.multiply(count_disc_ind.values)\n",
    "disc_w_ind = disc_df.filter(range(0,101)).multiply(count_disc_ind.values)\n",
    "disc_repeat_w_ind = disc_repeat.multiply(count_disc_ind.values)\n",
    "no_disc_w_ind = no_disc.multiply(count_disc_ind.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_df[\"avg_all\"] = disc_w.mean(axis=1, skipna=True)\n",
    "\n",
    "disc_df[\"avg_repeated\"] = disc_repeat_w[disc_repeat_w>0].mean(axis=1, skipna=True)\n",
    "\n",
    "disc_df[\"avg_added\"] = disc_diff_w[disc_diff_w>0].mean(axis=1, skipna=True)\n",
    "\n",
    "disc_df[\"avg_removed\"] = disc_diff_w[disc_diff_w<0].mean(axis=1, skipna=True)\n",
    "\n",
    "disc_df[\"avg_nodisc\"] = no_disc_w.mean(axis=1, skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_df[\"avg_all_ind\"] = disc_w_ind.mean(axis=1, skipna=True)\n",
    "\n",
    "disc_df[\"avg_repeated_ind\"] = disc_repeat_w_ind[disc_repeat_w_ind>0].mean(axis=1, skipna=True)\n",
    "\n",
    "disc_df[\"avg_added_ind\"] = disc_diff_w_ind[disc_diff_w_ind>0].mean(axis=1, skipna=True)\n",
    "\n",
    "disc_df[\"avg_removed_ind\"] = disc_diff_w_ind[disc_diff_w_ind<0].mean(axis=1, skipna=True)\n",
    "\n",
    "disc_df[\"avg_nodisc_ind\"] = no_disc_w_ind.mean(axis=1, skipna=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EIKON prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Instrument', 'CLOSEPRICE', 'VOLUME', 'COMPANYMARKETCAP',\n",
       "       'TTLCMNSHARESOUT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices_df = pd.read_csv(\"Data\\Prices.csv\")\n",
    "prices_df[\"Date\"] = pd.to_datetime(prices_df[\"Date\"])\n",
    "prices_df.sort_values([\"Instrument\", \"Date\"], inplace=True)\n",
    "prices_df = prices_df[prices_df[\"Date\"]>'2005-01-01'].set_index('Date')\n",
    "prices_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily shares turnover\n",
    "prices_df[\"SHRTURN\"] = prices_df[\"VOLUME\"] / prices_df[\"TTLCMNSHARESOUT\"]\n",
    "\n",
    "# Returns\n",
    "prices_df[\"Return\"] = prices_df.groupby(\"Instrument\")[\"CLOSEPRICE\"].pct_change(1)\n",
    "\n",
    "prices_df[\"log_Return\"] = np.log(prices_df[\"Return\"] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time window\n",
    "N = 20\n",
    "\n",
    "# Average of N-day std of daily returns\n",
    "std_returns = (\n",
    "    prices_df.groupby(\"Instrument\")[\"Return\"]\n",
    "    .rolling(N, min_periods=N//2).std().to_frame()\n",
    ")\n",
    "std_returns[f\"stdReturn+{N}\"] = std_returns.groupby(\"Instrument\")[\"Return\"].shift(-N-2)\n",
    "std_returns[f\"stdReturn_{N}\"] = std_returns.groupby(\"Instrument\")[\"Return\"].shift(2)\n",
    "\n",
    "# std_returns.drop(columns=\"log_Return\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of N-day trade volumes\n",
    "N=5\n",
    "MA_vol = prices_df.groupby(\"Instrument\")[\"VOLUME\"].rolling(N, min_periods=3).mean().to_frame()\n",
    "MA_vol[f\"VOLUME\"] = MA_vol.groupby(\"Instrument\")[\"VOLUME\"].shift(N//2)\n",
    "MA_vol[\"SHRTURN\"] = prices_df.groupby(\"Instrument\")[\"SHRTURN\"].rolling(N, min_periods=3).mean()\n",
    "MA_vol[f\"SHRTURN\"] = MA_vol.groupby(\"Instrument\")[\"SHRTURN\"].shift(N//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time window\n",
    "N = 30\n",
    "\n",
    "# Average of 60-day std of daily returns\n",
    "std_returns[f\"stdReturn+{N}\"] = prices_df.groupby(\"Instrument\")[\"Return\"].rolling(N, min_periods=N//2).std().groupby(\"Instrument\").shift(-N-2)\n",
    "std_returns[f\"stdReturn_{N}\"] = prices_df.groupby(\"Instrument\")[\"Return\"].rolling(N, min_periods=N//2).std().groupby(\"Instrument\").shift(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bid-Ask spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 8687523 entries, 2006-01-17 to 2022-06-14\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   Instrument  int64  \n",
      " 1   HIGHPRICE   float64\n",
      " 2   LOWPRICE    float64\n",
      " 3   BIDPRICE    float64\n",
      " 4   ASKPRICE    float64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 397.7 MB\n"
     ]
    }
   ],
   "source": [
    "BidAsk_df = pd.read_csv(\"Data\\BidAsk.csv\").drop_duplicates()\n",
    "BidAsk_df[\"Date\"] = pd.to_datetime(BidAsk_df[\"Date\"])\n",
    "BidAsk_df.set_index('Date', inplace=True)\n",
    "BidAsk_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BidAsk_df[\"BAspread\"] = (BidAsk_df[\"ASKPRICE\"] - BidAsk_df['BIDPRICE'])/BidAsk_df[\"ASKPRICE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "\n",
    "# N-day moving average (trading days only)\n",
    "MA_BA = BidAsk_df.groupby('Instrument')['BAspread'].rolling(N, min_periods=N//2).mean().to_frame()\n",
    "MA_BA[f\"avgBA+{N}\"] = MA_BA.groupby(\"Instrument\")[\"BAspread\"].shift(-N-2)\n",
    "MA_BA[f\"avgBA_{N}\"] = MA_BA.groupby(\"Instrument\")[\"BAspread\"].shift(2)\n",
    "\n",
    "MA_BA.drop(columns='BAspread', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 30\n",
    "# N-day moving average (trading days only)\n",
    "MA_BA[f\"avgBA+{N}\"] = BidAsk_df.groupby('Instrument')['BAspread'].rolling(N, min_periods=N//2).mean().groupby(\"Instrument\").shift(-N-2)\n",
    "MA_BA[f\"avgBA_{N}\"] = BidAsk_df.groupby('Instrument')['BAspread'].rolling(N, min_periods=N//2).mean().groupby(\"Instrument\").shift(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Instrument', 'Beta_30', 'Beta_90', 'Beta_250', 'AR', 'CAR_10',\n",
       "       'CAR_20', 'CAR_30'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Beta = pd.read_csv(\"Data\\Beta_AR.csv\")\n",
    "Beta.drop_duplicates(inplace=True)\n",
    "Beta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta['Date'] = pd.to_datetime(Beta['Date'])\n",
    "Beta.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Beta\n",
    "Beta[\"BETA+30\"] = Beta.groupby('Instrument')[\"Beta_30\"].shift(-30-2)\n",
    "Beta[\"BETA_30\"] = Beta.groupby('Instrument')[\"Beta_30\"].shift(2)\n",
    "\n",
    "Beta[\"BETA+90\"] = Beta.groupby('Instrument')[\"Beta_90\"].shift(-90-2)\n",
    "Beta[\"BETA_90\"] = Beta.groupby('Instrument')[\"Beta_90\"].shift(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Analysts = pd.read_csv(\"Data\\Analysts.csv\")\n",
    "Analysts.dropna(inplace=True)\n",
    "\n",
    "Analysts.columns = ['Instrument', 'NUMBEROFANALYSTS', 'Date']\n",
    "Analysts['Date'] = pd.to_datetime(Analysts['Date'], errors='coerce').dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Analyst_df = pd.merge(\n",
    "    left=prices_df[\"Instrument\"], \n",
    "    right=Analysts, \n",
    "    on=[\"Date\", \"Instrument\"],\n",
    "    how=\"outer\"\n",
    ")\n",
    "\n",
    "Analyst_df = Analyst_df[(Analyst_df[\"Date\"]>'2005-01-01')&(Analyst_df[\"Date\"]<'2023-01-01')]\n",
    "\n",
    "Analyst_df.sort_values(['Instrument', 'Date', 'NUMBEROFANALYSTS'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Analyst_df[\"NUMBEROFANALYSTS\"] = Analyst_df.groupby(\"Instrument\")[\"NUMBEROFANALYSTS\"].fillna(method='ffill')\n",
    "Analyst_df.drop_duplicates(subset=['Instrument', 'Date'], keep='last', inplace=True)\n",
    "Analyst_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annual financial data\n",
    "# Fill NAs with last (previouse) observation and drop duplicates\n",
    "financials = pd.read_csv(\n",
    "    filepath_or_buffer=\"Data\\Financials.csv\",\n",
    "    decimal=\".\", \n",
    "    thousands=',',\n",
    ").drop_duplicates()\n",
    "\n",
    "financials.sort_values(['cik', 'datadate'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials[\"datadate\"] = pd.to_datetime(financials[\"datadate\"], format=\"%d/%m/%Y\")\n",
    "financials[\"seq\"].fillna(financials[\"teq\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leverage\n",
    "financials[\"DtA\"] = financials[\"dt\"] / financials[\"at\"].replace(0, np.nan)\n",
    "financials[\"DtEBITDA\"] = financials[\"dt\"] / financials[\"ebitda\"].replace(0, np.nan)\n",
    "\n",
    "# Profitability\n",
    "financials[\"ROE\"] = financials[\"ni\"] / financials[\"seq\"].replace(0, np.nan)\n",
    "financials[\"NPM\"] = financials[\"ni\"] / financials[\"revt\"].replace(0, np.nan) # net profit margin\n",
    "\n",
    "# Firm size\n",
    "financials[\"logMC\"] = np.log(financials[\"mkvalt\"].replace(0, np.nan))\n",
    "financials[\"logTA\"] = np.log(financials[\"at\"].replace(0, np.nan))\n",
    "\n",
    "# Intangible assets\n",
    "financials[\"RtINT\"] = financials[\"revt\"] / financials[\"intan\"].replace(0, np.nan)\n",
    "financials[\"INTtA\"] = financials[\"intan\"] / financials[\"at\"].replace(0, np.nan) \n",
    "\n",
    "# Liquidity\n",
    "financials[\"current\"] = financials[\"act\"] / financials[\"lct\"].replace(0, np.nan)\n",
    "\n",
    "# Other\n",
    "financials[\"TobinQ\"] = financials[\"mkvalt\"] / financials[\"at\"].replace(0, np.nan)\n",
    "financials[\"BtM\"] = financials[\"seq\"] / financials[\"mkvalt\"].replace(0, np.nan)\n",
    "\n",
    "# R&D intensity\n",
    "financials[\"RDxopr\"] = financials[\"xrd\"].fillna(0) / financials[\"xopr\"].replace(0, np.nan)\n",
    "financials[\"ProprietaryCost\"] = financials[\"xrd\"].fillna(0) / financials.groupby('cik')[\"at\"].shift(1).replace(0, np.nan)\n",
    "\n",
    "# %change in earnings\n",
    "financials[\"DEarnings\"] = financials.groupby(\"cik\")[\"ni\"].pct_change(1).replace(np.Inf, np.nan)\n",
    "financials[\"DEarnings\"].replace(-np.Inf, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials['naicsh'] = financials['naicsh'].fillna(financials['naics']).astype(int)\n",
    "financials['sich'] = financials['sich'].fillna(financials['sic']).astype(int)\n",
    "\n",
    "# First 3 digits of historical NAICS > Subsector\n",
    "financials['naicsh'] = financials['naicsh'].map(lambda x: str(x)[:3])\n",
    "\n",
    "# First 2 digits of historical SIC > Major sector group\n",
    "financials['sich'] = financials['sich'].map(lambda x: str(x)[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gvkey', 'datadate', 'fyear', 'indfmt', 'consol', 'popsrc', 'datafmt',\n",
       "       'curcd', 'act', 'at', 'dt', 'ebit', 'ebitda', 'intan', 'lct', 'lt',\n",
       "       'ni', 'revt', 'seq', 'teq', 'xopr', 'xrd', 'xt', 'cik', 'costat',\n",
       "       'naicsh', 'sich', 'mkvalt', 'naics', 'sic', 'DtA', 'DtEBITDA', 'ROE',\n",
       "       'NPM', 'logMC', 'logTA', 'RtINT', 'INTtA', 'current', 'TobinQ', 'BtM',\n",
       "       'RDxopr', 'ProprietaryCost', 'DEarnings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financials.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_data = pd.merge(\n",
    "    left=stat_data,\n",
    "    right=std_returns,\n",
    "    left_on=[\"CIK\", \"filing_dt\"],\n",
    "    right_index=True,\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "stat_data = pd.merge(\n",
    "    left=stat_data,\n",
    "    right=MA_vol,\n",
    "    left_on=[\"CIK\", \"filing_dt\"],\n",
    "    right_index=True,\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "stat_data = pd.merge(\n",
    "    left=stat_data,\n",
    "    right=MA_BA,\n",
    "    left_on=[\"CIK\", \"filing_dt\"],\n",
    "    right_index=True,\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_data = pd.merge(\n",
    "    left=stat_data,\n",
    "    right=Beta.reset_index()[[\n",
    "        'Instrument', 'Date', \n",
    "        'BETA+30', 'BETA_30', 'BETA+90', 'BETA_90',\n",
    "        'CAR_10', 'CAR_20', 'CAR_30'\n",
    "    ]],\n",
    "    left_on=[\"CIK\", \"filing_dt\"],\n",
    "    right_on=['Instrument', 'Date'],\n",
    "    how=\"left\"\n",
    ").drop(columns=['Instrument', 'Date'])\n",
    "\n",
    "stat_data = pd.merge(\n",
    "    left=stat_data,\n",
    "    right=Analyst_df[['Date', 'Instrument', 'NUMBEROFANALYSTS']],\n",
    "    left_on=[\"CIK\", \"filing_dt\"],\n",
    "    right_on=['Instrument', 'Date'],\n",
    "    how=\"left\"\n",
    ").drop(columns=['Instrument', 'Date'])\n",
    "# stat_data['NUMBEROFANALYSTS'].fillna(0, inplace=True)\n",
    "\n",
    "stat_data = pd.merge(\n",
    "    left=stat_data,\n",
    "    right=financials[[\n",
    "        'cik', 'datadate', 'naicsh', 'DtA', 'DtEBITDA', 'ROE', 'NPM', 'mkvalt', 'logMC',\n",
    "        'at', 'logTA', 'RtINT', 'INTtA', 'current', 'TobinQ', 'BtM', 'RDxopr', 'ProprietaryCost', 'DEarnings'\n",
    "    ]],\n",
    "    left_on=[\"CIK\", \"report_dt\"],\n",
    "    right_on=[\"cik\", \"datadate\"],\n",
    "    how=\"left\"\n",
    ").drop(columns=['datadate', 'cik'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_data = pd.merge(\n",
    "    left=stat_data,\n",
    "    right=disc_df[[\n",
    "        'CIK', 'filing_dt', 'report_dt', 'avg_all', 'avg_repeated', 'avg_added', 'avg_removed', 'avg_nodisc',\n",
    "        'avg_all_ind', 'avg_repeated_ind', 'avg_added_ind', 'avg_removed_ind', 'avg_nodisc_ind'\n",
    "    ]],\n",
    "    on=[\"CIK\", \"filing_dt\", \"report_dt\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CIK', 'rprt_length', 'SIC', 'Industry', 'category', 'reported_crnt',\n",
       "       'reported_last', 'repeated', 'added', 'removed', 'rfGap', 'fyear',\n",
       "       'ryear', 'Return', 'stdReturn+20', 'stdReturn_20', 'stdReturn+30',\n",
       "       'stdReturn_30', 'VOLUME', 'SHRTURN', 'avgBA+20', 'avgBA_20', 'avgBA+30',\n",
       "       'avgBA_30', 'BETA+30', 'BETA_30', 'BETA+90', 'BETA_90', 'CAR_10',\n",
       "       'CAR_20', 'CAR_30', 'NUMBEROFANALYSTS', 'naicsh', 'DtA', 'DtEBITDA',\n",
       "       'ROE', 'NPM', 'mkvalt', 'logMC', 'at', 'logTA', 'RtINT', 'INTtA',\n",
       "       'current', 'TobinQ', 'BtM', 'RDxopr', 'ProprietaryCost', 'DEarnings',\n",
       "       'avg_all', 'avg_repeated', 'avg_added', 'avg_removed', 'avg_nodisc',\n",
       "       'avg_all_ind', 'avg_repeated_ind', 'avg_added_ind', 'avg_removed_ind',\n",
       "       'avg_nodisc_ind'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_data['Industry'] = stat_data['Industry'].map(lambda x: re.sub('Office of ', '', x[0]))\n",
    "stat_data[\"category\"] = stat_data[\"category\"].map(lambda x: x[0])\n",
    "\n",
    "stat_data.drop(columns=['filing_dt', 'report_dt'], inplace=True)\n",
    "stat_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28194, 59)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_data.to_csv(f'Data\\stats_data_T2V_H_V3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ETM_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e814d5f901f2e2f1812217256e7a2386c6b3dac449e52472436b21a420d1617"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
